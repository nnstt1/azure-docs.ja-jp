---
title: AutoML でのオーバーフィット データと不均衡データの回避
titleSuffix: Azure Machine Learning
description: Azure Machine Learning の自動機械学習ソリューションを使用して、ML モデルの一般的な落とし穴を特定し、管理します。
services: machine-learning
ms.service: machine-learning
ms.subservice: automl
ms.topic: conceptual
ms.reviewer: nibaccam
author: nibaccam
ms.author: nibaccam
ms.date: 10/21/2021
ms.openlocfilehash: 841537cdf506326c810fee9ceec501145fb5f98e
ms.sourcegitcommit: e41827d894a4aa12cbff62c51393dfc236297e10
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/04/2021
ms.locfileid: "131559069"
---
# <a name="prevent-overfitting-and-imbalanced-data-with-automated-machine-learning"></a>自動機械学習でのオーバーフィット データと不均衡データを防止する

機械学習モデルを構築する際に陥りやすい落とし穴が、オーバーフィットやデータの偏りです。 既定では、Azure Machine Learning の自動機械学習は、これらのリスクを特定するのに役立つグラフとメトリックを提供し、リスクを軽減するためのベスト プラクティスを実装します。 

## <a name="identify-overfitting"></a>オーバーフィットを特定する

機械学習のオーバーフィットは、モデルがトレーニング データに過剰にフィットする場合に発生します。結果として、未見のテスト データで正確な予測を実行できなくなります。 言い換えると、モデルは、トレーニング データ内の特定のパターンや不要な情報を単に記憶しただけで、実際のデータで予測を行うだけの十分な柔軟性がありません。

次のトレーニング済みモデルと、それに対応するトレーニングとテストの精度について検討します。

| モデル | トレーニングの精度 | テストの精度 |
|-------|----------------|---------------|
| A | 99.9% | 95% |
| B | 87% | 87% |
| C | 99.9% | 45% |

モデル **A** では、未見のデータに対するテストの精度が、トレーニングの精度よりも低くなっています。この場合に、モデルがオーバーフィットしていると認識するのはよくある誤認です。 テストの精度は常にトレーニングの精度よりも低くなるものであり、精度低下の *程度* によってオーバーフィットか、適切なフィットかを判断します。 

モデル **A** とモデル **B** を比較した場合、モデル **A** の方がテストの精度が高いため適切なモデルです。モデル A は、テストの精度がトレーニングの精度よりやや低い 95% ですが、これはオーバーフィットが発生していることを示す大きな差ではありません。 トレーニングの精度とテストの精度が非常に近いという単純な理由で、モデル **B** は選択しません。

モデル **C** は、オーバーフィットが発生していることを明確に表しています。トレーニングの精度が非常に高い一方で、テストの精度はまったく高くありません。 この見分け方は主観的ですが、問題とデータの知識、および許容できる誤差の大きさから得られるものです。

## <a name="prevent-overfitting"></a>オーバーフィットを防ぐ

最も極端なケースでは、オーバーフィットしたモデルは、トレーニング中に検出された特徴値の組み合わせが、常にターゲットのまったく同じ出力になります。

オーバーフィットを防ぐ最も適切な方法は、次のような ML のベスト プラクティスに従うことです。

* より多くのトレーニング データを使用し、統計的偏りを排除する
* ターゲット漏えいを防ぐ
* 使用する機能の削減
* **正則化とハイパーパラメーターの最適化**
* **モデルの複雑さの制限**
* **クロス検証**

自動 ML のコンテキストでは、上記の最初の 3 つの項目は、**ユーザーが実装するベスト プラクティス** です。 最後の 3 つの太字の項目は、オーバーフィットを防ぐために既定で **自動 ML により実装されるベスト プラクティス** です。 自動 ML 以外の設定でも、モデルのオーバーフィットを回避するために、6 つのベスト プラクティスすべてに従うことをお勧めします。

## <a name="best-practices-you-implement"></a>ユーザーが実装するベスト プラクティス

### <a name="use-more-data"></a>より多くのデータを使用する

**より多くのデータ** を使用することは、オーバーフィットを防ぐための最も簡単で最も効果的な方法です。また、追加の利点として、通常は精度が向上します。 より多くのデータを使用すると、モデルは正確なパターンを記憶することが困難になり、より多くの条件に対応するより柔軟な解を導き出さざるを得なくなります。 また、**統計的偏り** を認識して、実際の予測データに存在しないような分離パターンがトレーニング データに含まれないようにすることも重要です。 このシナリオは解決するのが困難な場合があります。これは、トレーニング セットとテスト セットの間でオーバーフィットが発生しない可能性がある一方で、実際のテスト データと比較した場合に、オーバーフィットが発生する可能性があるためです。

### <a name="prevent-target-leakage"></a>ターゲット漏えいを防ぐ

**ターゲット漏えい** は同様の問題であり、トレーニング セットとテスト セットの間でオーバーフィットが確認されない一方で、予測時にこれが現れる可能性があります。 ターゲット漏えいは、モデルが予測時には通常使用しないデータにトレーニング中にアクセスすることで、"ずる" を行うと発生します。 たとえば、問題が、金曜日に商品価格がどのようになるかを月曜日に予測することであるときに、いずれかの特徴に木曜日のデータが誤って含まれている場合、それは予測時にモデルが使用しないデータです。未来は調べることができないためです。 ターゲット漏えいは、見逃しやすいミスですが、問題に対して異常に精度が高いという特色が多くの場合発生します。 株価を予測し、95% の精度でモデルをトレーニングした場合、特徴のどこかにターゲット漏えいがある可能性が高くなります。

### <a name="use-fewer-features"></a>使用する特徴を減らす

**特徴を削除すること** が、オーバーフィットで役立つ場合もあります。これは、モデルで特定のパターンを記憶するために使用するフィールドが多くなりすぎるのを防ぎ、柔軟性を向上させます。 定量的な測定は困難な場合がありますが、特徴を削除しても同じ精度を維持できる場合、モデルの柔軟性が向上し、オーバーフィットのリスクが軽減された可能性が高いと言えます。

## <a name="best-practices-automated-ml-implements"></a>自動 ML により実装されるベスト プラクティス

### <a name="regularization-and-hyperparameter-tuning"></a>正則化とハイパーパラメーターのチューニング

**正則化** は、オーバーフィットした複雑なモデルにペナルティーを科すためのコスト関数を最小化するプロセスです。 さまざまな種類の正則化関数がありますが、一般に、これらはすべて、モデルの係数サイズ、分散、および複雑さに対してペナルティーを科します。 自動 ML では、オーバーフィットを制御するさまざまなモデル ハイパーパラメーター設定と共に、L1 (Lasso)、L2 (Ridge)、ElasticNet (L1 と L2 を同時使用) がさまざまな組み合わせで使用されます。 簡単に言うと、自動 ML は、モデルをどの程度規制するかを変えて、最適な結果を選択します。

### <a name="model-complexity-limitations"></a>モデルの複雑さの制限

自動 ML では、オーバーフィットを防ぐために、明示的な **モデルの複雑さの制限** も実装されます。 ほとんどの場合、この実装は、特にデシジョン ツリーまたはフォレスト アルゴリズム用です。ここでは、個々のツリーの最大深度が制限され、さらにフォレストまたはアンサンブル手法で使用されるツリーの合計数が制限されます。

### <a name="cross-validation"></a>クロス検証

**クロス検証 (CV)** は、全トレーニング データのサブセットを多く取得し、各サブセットでモデルをトレーニングするプロセスです。 これは、モデルは、"運がよい" 場合に、1 つのサブセットで高い精度を実現できる可能性があるが、多くのサブセットを使用することで、モデルはこの高い精度を毎回は達成できないという考え方です。 CV を実行する場合、検証の予約データセットを指定し、CV フォールド (サブセットの数) を指定します。自動 ML は、モデルをトレーニングし、ハイパーパラメーターを調整して検証セットのエラーを最小限に抑えます。 CV フォールドが 1 つでは、オーバーフィットとなる可能性がありますが、それらを多数使用することで、最終的なモデルがオーバーフィットする確率は低下します。 このトレードオフとして、CV ではトレーニング時間が長くなり、コストが高くなります。これは、モデルを一度にトレーニングするのではなく、*n* 個の各 CV サブセットで 1 回ずつトレーニングするためです。 

> [!NOTE]
> クロス検証は既定では有効になっていません。自動 ML 設定で構成する必要があります。 ただし、クロス検証を構成し、検証データセットを用意した後は、プロセスは自動化されます。 [自動 ML でのクロス検証の詳細については、こちらを参照してください](how-to-configure-cross-validation-data-splits.md)

<a name="imbalance"></a>

## <a name="identify-models-with-imbalanced-data"></a>偏ったデータを含むモデルを特定する

偏ったデータは、機械学習の分類シナリオのデータでよく見られるもので、各クラスに不適切な観測比率を含むデータを意味します。 この不均衡によって、入力データが 1 つのクラスに偏り、トレーニングされたモデルがその偏りを再現するため、モデルの精度に擬陽性の影響が生じる可能性があります。 

さらに、自動 ML を実行すると、次のグラフが自動的に生成されます。これは、モデルの分類の正確性を把握し、偏ったデータの影響を受ける可能性のあるモデルを特定するのに役立ちます。

グラフ| 説明
---|---
[混同行列](how-to-understand-automated-ml.md#confusion-matrix)| 適切に分類されたラベルをデータの実際のラベルと比較して評価します。 
[精度/再現率](how-to-understand-automated-ml.md#precision-recall-curve)| 適切なラベルの比率を、検出されたデータのラベル インスタンスの比率と比較して評価します 
[ROC 曲線](how-to-understand-automated-ml.md#roc-curve)| 適切なラベルの比率を、擬陽性ラベルの比率と比較して評価します。

## <a name="handle-imbalanced-data"></a>偏ったデータの処理 

機械学習ワークフローを簡略化する目標の一環として、以下のような偏ったデータを処理するための **機能が自動 ML に組み込まれています**。 

- **重み列**: 自動 ML では、重みの列が入力としてサポートされているため、データ内の行が重み付けされ、これを使用してクラスの "重要度" を増減できます。

- 自動 ML によって使用されるアルゴリズムでは、少数派クラスのサンプルの数が多数派クラスのサンプル数の 20% 以下である場合に不均衡を検出します。この場合、少数派クラスとはサンプルが最も少ないものを指し、多数派クラスとはサンプルが最も多いものを指します。 その後、AutoML は、サブサンプリングされたデータを使用して実験を実行し、クラスの重みを使用してこの問題を解決し、パフォーマンスを向上させるかどうかを確認します。 この実験によってパフォーマンスの向上が確認された場合は、この解決方法が適用されます。

- 偏ったデータをより適切に処理するパフォーマンス メトリックを使用します。 たとえば、AUC_weighted は、そのクラスを表すサンプルの相対的な数に基づいてすべてのクラスの貢献度を計算する主要なメトリックであるため、不均衡に対してはより堅牢です。

次の手法は、**自動 ML の外部** で偏ったデータを処理するための追加のオプションです。 

- より小さいクラスをアップサンプリングするか、より大きいクラスをダウンサンプリングすることで、クラスの偏りを均等にするための再サンプリング。 これらの方法では、処理および分析するための専門知識が必要です。

- 偏ったデータのパフォーマンス メトリックを確認します。 たとえば F1 スコアは、精度とリコールの調和平均です。 精度では分類子の正確性が測定され、高精度は擬陽性の数が少ないことを示します。リコールでは分類子の完全性が測定されて、高いリコールは擬陰性の数が少ないことを示します。

## <a name="next-steps"></a>次のステップ

例を参照して、自動化された機械学習を使用してモデルを構築する方法を学習してください。

+ 次のチュートリアルを修了してください。[チュートリアル:Azure Machine Learning で回帰モデルを自動的にトレーニングする](tutorial-auto-train-models.md)

+ 自動トレーニング実験の設定を構成してください。
  + Azure Machine Learning Studio で、[こちらの手順](how-to-use-automated-ml-for-ml-models.md)を使用します。
  + Python SDK で、[こちらの手順](how-to-configure-auto-train.md)を使用します。
