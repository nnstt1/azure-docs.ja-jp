---
title: PyTorch モデルのトレーニング
titleSuffix: Azure Machine Learning
description: Azure Machine Learning デザイナーの Pytorch モデルのトレーニング コンポーネントを使用して、モデルを最初からトレーニングする、または既存のモデルを微調整します。
services: machine-learning
ms.service: machine-learning
ms.subservice: core
ms.topic: reference
author: likebupt
ms.author: keli19
ms.date: 03/19/2021
ms.openlocfilehash: 0d2bf3b403aab29f0e47fd8aac1aa935acb31dd5
ms.sourcegitcommit: e41827d894a4aa12cbff62c51393dfc236297e10
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/04/2021
ms.locfileid: "131565735"
---
# <a name="train-pytorch-model"></a>PyTorch モデルのトレーニング

この記事では、Azure Machine Learning デザイナーで **PyTorch モデルのトレーニング** コンポーネントを使用して、DenseNet などの Pytorch モデルをトレーニングする方法について説明します。 トレーニングは、モデルを定義してそのパラメーターを設定した後に行なわれ、これにはラベル付けされたデータが必要です。 

現在、**PyTorch モデルのトレーニング** コンポーネントでは、単一ノードと分散の両方のトレーニングをサポートしています。

## <a name="how-to-use-train-pytorch-model"></a>PyTorch モデルのトレーニングを使用する方法 

1. デザイナーで [DenseNet](densenet.md) コンポーネントまたは [ResNet](resnet.md) をパイプライン ドラフトに追加します。

2. **PyTorch モデルのトレーニング** コンポーネントをパイプラインに追加します。 このコンポーネントは、 **[モデル トレーニング]** カテゴリにあります。 **[トレーニング]** を展開し、**PyTorch モデルのトレーニング** コンポーネントをパイプラインにドラッグします。

   > [!NOTE]
   > **PyTorch モデルのトレーニング** コンポーネントは、大規模なデータセットについては **GPU** 型のコンピューティングで実行することが推奨されます。それ以外の場合、パイプラインは失敗します。 コンポーネントの右側のウィンドウで特定のコンポーネントを計算するよう選択するには、 **[Use other compute target]\(その他のコンピューティング先を使用する\)** を設定します。

3.  左側の入力に、未トレーニングのモードをアタッチします。 トレーニング データセットと検証データセットを **PyTorch モデルのトレーニング** の中央および右側の入力にアタッチします。

    未トレーニングのモデルでは、DenseNet のような PyTorch モデルを使用する必要があります。それ以外の場合は、'InvalidModelDirectoryError' がスローされます。

    データセットの場合、トレーニング データセットはラベル付けされたイメージ ディレクトリである必要があります。 ラベル付けされたイメージ ディレクトリを取得する方法については、「**イメージ ディレクトリへの変換**」を参照してください。 ラベル付けされていない場合は、'NotLabeledDatasetError' がスローされます。

    トレーニング データセットと検証データセットのラベル カテゴリは同じです。それ以外の場合は、InvalidDatasetError がスローされます。

4.  **[Epochs]\(エポック\)** には、トレーニングするエポック数を指定します。 データセット全体は、エポック毎に反復されます。既定値は 5 です。

5.  **[Batch size]\(バッチ サイズ\)** には、バッチでトレーニングするインスタンスの数を指定します。既定値は 16 です。

6.  **[ウォームアップ ステップ数]** には、初期学習率がわずかに高すぎて収束が開始しない場合にトレーニングをウォームアップするエポック数を指定します。既定値は 0 です。

7.  **[学習率]** には、*学習率* の値を指定します。既定値は 0.001 です。 学習率は、モデルがテストされて修正されるたびに、SGD のようなオプティマイザーで使用されるステップのサイズを制御します。

    率を小さく設定すると、モデルのテストが頻繁に実行されますが、ローカルで停滞する可能性があります。 率を大きく設定すると、収束速度は速くなりますが、真の極小値から離れていってしまうおそれがあります。

    > [!NOTE]
    > トレーニング中にトレーニングの損失が NaN になった場合、これは高すぎる学習率が原因である可能性があり、学習率を下げると有効な場合があります。
    > 分散トレーニングでは、勾配降下を安定させるために、実際の学習率は `lr * torch.distributed.get_world_size()` によって計算されます。なぜなら、プロセス グループのバッチ サイズは、ワールドのサイズに単一プロセスのサイズを掛けたものだからです。
    > 多項式の学習率減衰が適用され、結果的にモデルのパフォーマンスの向上に寄与する可能性があります。

8.  **[Random seed]\(ランダム シード\)** には、必要に応じて、シードとして使用する整数値を入力します。 繰り返し実行したときの実験の再現性を確保したい場合は、シードを使用することをお勧めします。

9.  **[Patience]\(忍耐\)** には、検証の損失が連続して減少しない場合に、エポックがトレーニングを早期に停止する回数を指定します。 既定値は 3 です。

10. **[出力頻度]** には、各エポックのイテレーションでのトレーニング ログ出力頻度を指定します。既定値は 10 です。

11. パイプラインを送信します。 データセットのサイズが大きい場合は、しばらく時間がかかり、GPU コンピューティングが推奨されます。

## <a name="distributed-training"></a>分散トレーニング

分散トレーニングでは、モデルをトレーニングするためのワークロードが分割され、ワーカー ノードと呼ばれる複数のミニ プロセッサ間で共有されます。 これらのワーカー ノードは並行して動作し、モデルのトレーニングを高速化します。 現在、デザイナーでは、**PyTorch モデルのトレーニング** コンポーネントに対して分散トレーニングをサポートしています。

### <a name="training-time"></a>トレーニング時間

分散トレーニングを使用すると、ImageNet (1,000 クラス、120 万画像) のような大規模なデータセットを、**PyTorch モデルのトレーニング** によってわずか数時間でトレーニングすることが可能になります。 次の表は、ImageNet 上の Resnet50 の 50 エポックを、さまざまなデバイスに基づいて最初からトレーニングする間のトレーニング時間とパフォーマンスを示しています。

| デバイス       | トレーニング時間  | トレーニング スループット  | 上位 1 つの検証精度 | 上位 5 つの検証精度 |
| ------------- | -------------- | -------------------- | ------------------------- | ------------------------- |
| 16 個の V100 GPU  | 6 時間 22 分        | 3,200 画像/秒以下     | 68.83%                    | 88.84%                    | 
| 8 個の V100 GPU   | 12 時間 21 分       | 1,670 画像/秒以下     | 68.84%                    | 88.74%                    |

このコンポーネントの [メトリック] タブをクリックすると、"Train images per second" (1 秒あたりのトレーニング画像数) や "Top 1 accuracy" (1 位の精度) などのトレーニング メトリック グラフが表示されます。

[![トレーニングのメトリックを示すスクリーンショット](./media/module/train-pytorch-model-train-metrics.png)](././media/module/train-pytorch-model-train-metrics.png#lightbox)

### <a name="how-to-enable-distributed-training"></a>分散トレーニングを有効にする方法

**PyTorch モデルのトレーニング** コンポーネントに対して分散トレーニングを有効にするために、コンポーネントの右側のペインで **[実行設定]** を設定できます。 分散トレーニングでは **[AML コンピューティング クラスター](../how-to-create-attach-compute-cluster.md?tabs=python)** のみがサポートされています。

> [!NOTE]
> NCCL バックエンドの "PyTorch モデルのトレーニング" コンポーネントでは CUDA を使用する必要があるため、分散トレーニングをアクティブ化するには **複数の GPU** が必要です。

1. コンポーネントを選択して、右ペインを開きます。 **[実行設定]** セクションを展開します。

    [![runsetting で分散トレーニングを設定する方法を示すスクリーンショット](./media/module/distributed-training-run-setting.png)](./media/module/distributed-training-run-setting.png#lightbox)

2. コンピューティング先に対して AML コンピューティングが選択されていることを確認します。

3. **[リソース レイアウト]** セクションで、次の値を設定する必要があります。

    - **[ノード数]** : トレーニングに使用するコンピューティング先のノードの数。 コンピューティング クラスターの **[最大ノード数]** **以下** である必要があります。 既定値は 1 で、これは単一ノードのジョブを意味します。

    - **[ノードあたりのプロセス数]** : トリガーされたプロセスのノードあたりの数。 コンピューティングの **[処理単位]** **以下** である必要があります。 既定値は 1 で、これは単一プロセスのジョブを意味します。

    コンピューティングの **[最大ノード数]** および **[処理単位]** は、コンピューティングの詳細ページでコンピューティング名をクリックすると確認できます。

    [![コンピューティング クラスターの確認方法を示すスクリーンショット](./media/module/compute-cluster-node.png)](./media/module/compute-cluster-node.png#lightbox)

Azure Machine Learning での分散トレーニングの詳細については、[こちら](../concept-distributed-training.md)を参照してください。

### <a name="troubleshooting-for-distributed-training"></a>分散トレーニングのトラブルシューティング

このコンポーネントに対して分散トレーニングを有効にした場合、プロセスごとにドライバー ログが生成されます。 `70_driver_log_0` は、マスター プロセス用です。 右側のペインの **[出力とログ]** タブでは、各プロセスのエラーの詳細をドライバー ログから確認できます。

[![ドライバーのログを示すスクリーンショット](./media/module/distributed-training-error-driver-log.png)](./media/module/distributed-training-error-driver-log.png#lightbox) 

コンポーネント対応の分散トレーニングが `70_driver` ログなしで失敗した場合、`70_mpi_log` でエラーの詳細を確認できます。

次の例は、**ノードあたりのプロセス数** がコンピューティングの **処理単位** よりも大きいという一般的なエラーを示しています。

[![mpi ログを示すスクリーンショット](./media/module/distributed-training-error-mpi-log.png)](./media/module/distributed-training-error-mpi-log.png#lightbox)

コンポーネントのトラブルシューティングの詳細については、[こちらの記事](designer-error-codes.md)を参照してください。

## <a name="results"></a>結果

パイプラインの実行が完了した後、モデルをスコア付けに使用するには、[PyTorch モデルのトレーニング](train-PyTorch-model.md)を[画像モデルのスコア付け](score-image-model.md)に接続し、新しい入力例の値を予測します。

## <a name="technical-notes"></a>テクニカル ノート
###  <a name="expected-inputs"></a>想定される入力  

| 名前               | 種類                    | 説明                              |
| ------------------ | ----------------------- | ---------------------------------------- |
| 未トレーニング モデル    | UntrainedModelDirectory | 未トレーニング モデル、PyTorch が必要         |
| トレーニング データセット   | ImageDirectory          | トレーニング データセット                         |
| 検証データセット | ImageDirectory          | 各エポックを評価するための検証データセット |

###  <a name="component-parameters"></a>コンポーネントのパラメーター  

| 名前          | Range            | Type    | Default | 説明                              |
| ------------- | ---------------- | ------- | ------- | ---------------------------------------- |
| Epochs (エポック)        | >0               | Integer | 5       | ラベルまたは結果列を含む列を選択します |
| バッチ サイズ    | >0               | Integer | 16      | バッチでトレーニングするインスタンスの数   |
| ウォームアップ ステップ数 | >=0         | Integer | 0       | トレーニングをウォームアップするエポックの数 |
| Learning rate (学習率) | >=double.Epsilon | Float   | 0.1   | 確率的勾配降下法オプティマイザーの初期学習率。 |
| Random seed (ランダム シード)   | Any              | Integer | 1       | モデルで使用される乱数ジェネレーターのシードです。 |
| Patience (忍耐)      | >0               | Integer | 3       | トレーニングを早期に停止するエポックの数   |
| 出力頻度 |             >0 | Integer | 10      | 各エポックのイテレーションでのトレーニング ログ出力頻度 |

###  <a name="outputs"></a>出力  

| 名前          | 種類           | 説明   |
| ------------- | -------------- | ------------- |
| トレーニングされたモデル | ModelDirectory | トレーニングされたモデル |

## <a name="next-steps"></a>次のステップ

Azure Machine Learning で[使える一連のコンポーネント](component-reference.md)を参照してください。