---
title: Mapping data flow のパフォーマンスとチューニング ガイド
titleSuffix: Azure Data Factory & Azure Synapse
description: Azure Data Factory と Azure Synapse Analytics パイプラインでのマッピング データ フローのパフォーマンスに影響する主な要因について学習します。
author: kromerm
ms.topic: conceptual
ms.author: makromer
ms.service: data-factory
ms.subservice: data-flows
ms.custom: synapse
ms.date: 09/29/2021
ms.openlocfilehash: 7f12eb06d514ddc7d001012b0e3111c7603bdca9
ms.sourcegitcommit: 613789059b275cfae44f2a983906cca06a8706ad
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 09/29/2021
ms.locfileid: "129274047"
---
# <a name="mapping-data-flows-performance-and-tuning-guide"></a>Mapping Data Flow のパフォーマンスとチューニング ガイド

[!INCLUDE[appliesto-adf-asa-md](includes/appliesto-adf-asa-md.md)]

Azure Data Factory と Synapse パイプラインのマッピング データ フローには、大規模なデータ変換を設計および実行するためのコード不要のインターフェイスが用意されています。 マッピング データ フローに慣れていない場合は、[マッピング データ フローの概要](concepts-data-flow-overview.md)に関するページを参照してください。 この記事では、パフォーマンスのベンチマークを満たすようにデータ フローを調整および最適化するさまざまな方法について説明します。

こちらのビデオをご覧ください。データ フローを使用してデータを変換するサンプルのタイミングをいくつか紹介しています。

> [!VIDEO https://www.microsoft.com/en-us/videoplayer/embed/RE4rNxM]

## <a name="monitoring-data-flow-performance"></a>データ フローのパフォーマンスを監視する

デバッグ モードを使用して変換ロジックを確認したら、パイプラインでアクティビティとしてデータ フローをエンドツーエンドで実行します。 データ フローは、パイプラインで[データ フローの実行アクティビティ](control-flow-execute-data-flow-activity.md)を使用して運用可能にすることができます。 データ フロー アクティビティには、他のアクティビティと比較して独自の監視エクスペリエンスが用意されており、変換ロジックの詳細な実行プランとパフォーマンス プロファイルを表示できます。 データ フローの詳細な監視情報を表示するには、パイプラインのアクティビティの実行出力で眼鏡のアイコンをクリックします。 詳細については、[マッピング データ フローの監視](concepts-data-flow-monitoring.md)に関するページを参照してください。

:::image type="content" source="media/data-flow/monitoring-details.png" alt-text="データ フローの監視":::

データ フローのパフォーマンスを監視する際には、次の 4 つのボトルネックが考えられます。

* クラスターの起動時間
* ソースからの読み取り
* 変換時間
* シンクへの書き込み 

:::image type="content" source="media/data-flow/monitoring-performance.png" alt-text="データ フローの監視":::

クラスターの起動時間は、Apache Spark クラスターをスピンアップするためにかかる時間です。 この値は、監視画面の右上隅にあります。 データ フローは、各ジョブが分離クラスターを使用する Just-In-Time モデルで実行されます。 通常、この起動時間は 3 - 5 分かかります。 シーケンシャル ジョブの場合は、Time to Live を有効にすることで、これを短縮できます。 詳細については、「[Integration Runtime のパフォーマンス](concepts-integration-runtime-performance.md#time-to-live)」の「**Time to live**」セクションを参照してください。

データ フローには、可能な限り迅速な実行のためにビジネス ロジックを "ステージ" で並べ替えて実行する、Spark オプティマイザーが利用されます。 データ フローの書き込み先の各シンクについて、監視出力には、各変換ステージの期間と、シンクへのデータの書き込みにかかる時間が表示されます。 最大の時間は、データ フローのボトルネックになる可能性があります。 最も時間のかかる変換ステージにソースが含まれている場合は、読み取り時間をさらに最適化することをお勧めします。 変換に長い時間がかかっている場合は、統合ランタイムのパーティション再分割を行うか、サイズを増やす必要があります。 シンクの処理時間が長い場合は、データベースをスケールアップするか、1 つのファイルに出力していないことを確認する必要があります。

データ フローのボトルネックを特定したら、以下の最適化戦略を使用してパフォーマンスを向上させます。

## <a name="testing-data-flow-logic"></a>データ フローのロジックをテストする

UI からデータ フローを設計およびテストするときに、デバッグ モードを使用すれば、ライブ Spark クラスターに対して対話形式でテストできます。 これにより、クラスターがウォームアップされるのを待たずにデータをプレビューし、データ フローを実行することができます。 詳細については、[デバッグ モード](concepts-data-flow-debug-mode.md)に関するページを参照してください。

## <a name="optimize-tab"></a>[最適化] タブ

**[最適化]** タブには、Spark クラスターのパーティション分割を構成するための設定が含まれています。 データ フローのすべての変換に存在するこのタブでは、変換が完了した **後** にデータのパーティション再分割を行うかどうかを指定します。 パーティション分割を調整すると、全体的なデータ フローのパフォーマンスに好影響を与えることも、悪影響も与えることもある、各計算ノードへのデータの分散とデータの局所性の最適化を制御できます。

:::image type="content" source="media/data-flow/optimize.png" alt-text="パーティション オプション、パーティションの種類、パーティションの数が含まれる [最適化] タブが示されているスクリーンショット。":::

既定では、変換の現在の出力パーティション分割を維持するようサービスに指示する *[Use current partitioning]\(現在のパーティション分割を使用する\)* が選択されています。 データのパーティション再分割は時間がかかるため、ほとんどのシナリオでは、 *[Use current partitioning]\(現在のパーティション分割を使用する\)* をお勧めします。 データのパーティションを再分割する必要があるシナリオとしては、集計や結合によってデータが大幅にスキューされた場合や、SQL DB でソースのパーティション分割を使用する場合があります。

いずれかの変換でパーティション分割を変更する場合は、 **[最適化]** タブを選択し、 **[Set Partitioning]\(パーティションの設定\)** を選択します。 パーティション分割用の一連のオプションが表示されます。 パーティション分割の最適な方法は、データ ボリューム、候補キー、null 値、およびカーディナリティに応じて異なります。 

> [!IMPORTANT]
> すべての分散データを 1 つのパーティションに結合するのが単一パーティションです。 これは非常に低速な操作であると同時に、すべてのダウンストリームの変換と書き込みに大きな影響を及ぼします。 このオプションは、明示的なビジネス上の使用理由がない限り、推奨されません。

すべての変換で次のパーティション分割オプションを使用できます。

### <a name="round-robin"></a>ラウンド ロビン 

データを複数のパーティションに均等に分散するのがラウンド ロビンです。 堅固でスマートなパーティション分割戦略を実装するための適切な候補がないときは、ラウンド ロビンを使用します。 物理パーティションの数を設定できます。

### <a name="hash"></a>ハッシュ インデックス

サービスでは、同様の値を持つ行が同じパーティション内に分類されるように、列のハッシュを生成して統一されたパーティションを生成します。 [ハッシュ] オプションを使用するときは、起こり得るパーティションのスキューについてテストします。 物理パーティションの数を設定できます。

### <a name="dynamic-range"></a>動的範囲

動的範囲では、指定した列または式に基づく Spark の動的範囲が使用されます。 物理パーティションの数を設定できます。 

### <a name="fixed-range"></a>固定範囲

パーティション分割されたデータ列内の値に対する固定の範囲を提供する式を作成します。 パーティションのスキューを避けるため、このオプションを使用する際は、自分のデータについて十分に理解する必要があります。 式に入力する値は、パーティション関数の一部として使用されます。 物理パーティションの数を設定できます。

### <a name="key"></a>Key

データのカーディナリティを十分に理解している場合は、キー パーティション分割が適切な戦略になるでしょう。 キー パーティション分割では、列内の一意の値ごとにパーティションが作成されます。 パーティションの数は、データ内の一意の値に基づくため、設定することはできません。

> [!TIP]
> パーティション構成を手動で設定すると、データが再シャッフルされ、Spark オプティマイザーの利点が相殺される可能性があります。 必要な場合を除き、パーティション分割を手動で設定しないことをお勧めします。

## <a name="logging-level"></a>ログ記録レベル

データ フロー アクティビティのすべてのパイプラインを実行してすべての詳細なテレメトリ ログを完全にログする必要がない場合は、必要に応じてログ レベルを "基本" または "なし" に設定できます。 データ フローを [詳細] モード (既定値) で実行する場合、データ変換中に各パーティション レベルでアクティビティを完全にログするように、サービスに要求します。 これは負荷の高い操作であるため、トラブルシューティングを行うときにのみ詳細を有効にすることで、データ フローとパイプラインのパフォーマンス全体を向上させることができます。 "基本" モードでは、その変換の期間だけがログされるのに対し、"なし" を指定した場合は、期間の概要のみが提供されます。

:::image type="content" source="media/data-flow/logging.png" alt-text="ログ記録レベル":::

## <a name="next-steps"></a>次のステップ

- [ソースの最適化](concepts-data-flow-performance-sources.md)
- [シンクの最適化](concepts-data-flow-performance-sinks.md)
- [変換の最適化](concepts-data-flow-performance-transformations.md)
- [パイプラインでのデータ フローの使用](concepts-data-flow-performance-pipelines.md)

パフォーマンスに関する Data Flow のその他の記事を参照してください。

- [Data Flow のアクティビティ](control-flow-execute-data-flow-activity.md)
- [データ フローのパフォーマンスの監視](concepts-data-flow-monitoring.md)
- [Integration Runtime のパフォーマンス](concepts-integration-runtime-performance.md)
