---
title: よく寄せられる質問
description: Azure Object Anchors サービスに関する FAQ。
author: craigktreasure
manager: vriveras
ms.author: crtreasu
ms.date: 09/10/2021
ms.topic: overview
ms.service: azure-object-anchors
ms.openlocfilehash: 18069157b4c7f38216c01649a33ed5f999dc7577
ms.sourcegitcommit: f6e2ea5571e35b9ed3a79a22485eba4d20ae36cc
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 09/24/2021
ms.locfileid: "128638389"
---
# <a name="frequently-asked-questions-about-azure-object-anchors"></a>Azure Object Anchors についてよく寄せられる質問

Azure Object Anchors を使用すると、アプリケーションで 3D モデルを使用して現実世界のオブジェクトを検出し、その 6-DoF 姿勢を推定することができます。

詳しくは、「[Azure Object Anchors の概要](overview.md)」を参照してください。

## <a name="product-faq"></a>製品に関する FAQ
**Q: 使用するオブジェクトに関して、どのような推奨事項がありますか?**

**A:** 以下の特性を備えたオブジェクトが推奨されます。

* 各次元が 1-10 メートルである
* 非対称で、ジオメトリに十分な変化がある
* 反射率が低く (つや消し面) 色が明るい
* 静止したオブジェクトである
* 関節がない、または少ない
* 乱雑さがない、または最小限の、クリアな背景
* スキャンされたオブジェクトは、トレーニングに使用したモデルと 1:1 で一致している必要がある

**Q: モデルの変換で処理できるオブジェクトの最大ディメンションはどれくらいですか?**

**A:** CAD モデルの各次元は 10 メートル未満である必要があります。 詳細については、[資産の要件](overview.md)に関するページを参照してください。

**Q: 変換で処理できる CAD モデルの最大サイズはどれくらいですか?**

**A:** モデルのファイル サイズは 150 MB 未満である必要があります。 詳細については、[資産の要件](overview.md)に関するページを参照してください。

**Q: どのような CAD 形式がサポートされますか?**

**A:** 現在、`fbx`、`ply`、`obj`、`glb`、および `gltf` のファイルの種類がサポートされています。 詳細については、[資産の要件](overview.md)に関するページを参照してください。

**Q: モデル変換サービスで必要な重力方向と単位とは何ですか?**

**A:** 重力方向は地球を指す下方向のベクトルであり、測定単位はモデルのスケールを表します。 モデルを変換するときは、[重力の方向と資産の次元単位が正しいことを確認する](./troubleshoot/object-detection.md#ensure-the-gravity-direction-and-asset-dimension-unit-are-correct)ことが重要です。

**Q: CAD モデルの変換にはどれくらいの時間がかかりますか?**

**A:** `ply` モデルの場合は、通常 3-15 分です。 他の形式のモデルを送信する場合は、ファイル サイズに応じて 15-60 分の待機時間を想定してください。

**Q: モデル変換に失敗した場合、どうすれば復旧できますか?**

**A:** モデル変換ジョブが失敗した結果生成されるさまざまなエラー コードと、それぞれの処理方法の詳細については、[変換エラー コードに関するページ](.\model-conversion-error-codes.md)を参照してください。

**Q: Object Anchors ではどのようなデバイスがサポートされていますか?**

**A:** HoloLens 2 です。

**Q: HoloLens ではどの OS ビルドを実行する必要がありますか?**

**A:** OS ビルド 18363.720 以降 (2020 年 3 月 12 日以降にリリース) です。

  詳細については、[Windows 10 2020 年 3 月 12 日の更新](https://support.microsoft.com/help/4551762)を参照してください。

**Q: HoloLens でオブジェクトを検出するのにどれくらいの時間がかかりますか?**

**A:** オブジェクトのサイズとスキャン プロセスによって異なります。 迅速な検出を実現するには、詳細なスキャンのためのベスト プラクティスに従ってください。
各次元が 2 メートル以内の小さなオブジェクトの場合、検出は数秒以内に実行される可能性があります。 より大きなオブジェクト (車など) の場合、信頼性の高い検出を行うために、ユーザーはオブジェクトの周りを完全に一周する必要があります。つまり、検出に数十秒かかる可能性があります。

**Q: HoloLens アプリケーションで Object Anchors を使用する際のベスト プラクティスは何ですか?**

**A:**

 1. 正確なレンダリングを行うために、目のキャリブレーションを実行します。
 2. 部屋に豊富な視覚テクスチャと良好な照明を用意します。
 3. オブジェクトを動かさず、可能であれば乱雑さから遠ざけます。
 4. 必要に応じて、HoloLens デバイスの[空間マッピング](/windows/mixed-reality/spatial-mapping) キャッシュをクリアします。
 5. オブジェクトの周りを歩いてオブジェクトをスキャンします。 オブジェクトの大部分を観察するようにします。
 6. オブジェクトをカバーする十分に大きい検索領域を設定します。
 7. 検出中、オブジェクトは静止したままである必要があります。
 8. オブジェクトの検出を開始し、推定された姿勢に基づいてレンダリングを視覚化します。
 9. 姿勢が正確に安定したら、バッテリ寿命を保つために、検出されたオブジェクトをロックする、または追跡を停止します。

**Q: HoloLens Unity アプリケーションで Object Anchors Unity SDK を使用できるようにするには、どのバージョンの Mixed Reality Toolkit (MRTK) を使用する必要がありますか?**

**A:** Azure Object Anchors Unity SDK は、Mixed Reality Toolkit に一切依存していないため、任意のバージョンを自由に使用できます。 詳細については、「[Unity 用 MRTK の概要](/windows/mixed-reality/develop/unity/mrtk-getting-started)」を参照してください。

**Q: 推定された姿勢はどの程度正確ですか?**

**A:** オブジェクトのサイズ、素材、環境などによって異なります。小さいオブジェクトの場合、推定される姿勢は 2 cm 以内の誤差の可能性があります。 車のような大きなオブジェクトの場合、誤差は最大 2-8 cm になることがあります。

**Q: Object Anchors で動くオブジェクトを扱うことはできますか?**

**A:** **継続的に動く**、または **動的な** オブジェクトはサポートされていません。 オブジェクトを物理的に移動すると、空間内のまったく新しい位置でオブジェクトがサポートされますが、移動中は追跡できません。

**Q: Object Anchors で変形や関節を扱うことはできますか?**

**A:** 変形や関節によってオブジェクトの形やジオメトリがどの程度変化するかに応じて、部分的には可能です。 オブジェクトのジオメトリが頻繁に変化する場合、ユーザーはその構成に対して別のモデルを作成し、検出に使用することができます。

**Q: Object Anchors では、異なるモデルを同時に何個検出できますか?**

**A:** 現在、最適なユーザー エクスペリエンスを確保するために一度に 3 個のモデルを検出できますが、制限は適用されていません。

**Q: Object Anchors では、同じオブジェクト モデルの複数のインスタンスを検出することはできますか?**

**A:** はい。最適なユーザー エクスペリエンスを確保するために、同じ種類のモデルのインスタンスを最大 3 個検出することがサポートされていますが、制限は適用されていません。 検索領域ごとに 1 つのオブジェクト インスタンスを検出できます。 `ObjectQuery.SearchAreas.Add` を呼び出すことによって、クエリに検索領域を追加して、より多くのインスタンスを検出できます。 複数のクエリで `ObjectObserver.DetectAsync` を呼び出して、複数のモデルを検出できます。

**Q: Object Anchors ランタイムによってオブジェクトが検出されない場合は、どうすればよいですか?**

**A:** 環境、モデル変換の構成、クエリの設定など、オブジェクトの正しい検出を妨げる可能性がある多くの要因があります。 [オブジェクト検出のトラブルシューティング](./troubleshoot/object-detection.md)方法の詳細を確認してください。

**Q: オブジェクトのクエリ パラメーターはどのように選択すればよいですか?**

**A:** こちらの[一般的なガイダンス](./troubleshoot/object-detection.md#adjust-object-query-values)と[検出が困難なオブジェクト](./detect-difficult-object.md)の詳細なガイドを参照してください。

**Q: HoloLens から Object Anchors の診断データを取得するにはどうすればよいですか?**

**A:** アプリケーションでは、診断情報のアーカイブの場所を指定できます。 Object Anchors のサンプル アプリでは、**TempState** フォルダーに診断情報が書き込まれます。

**Q: Object Anchors Unity SDK によって返された姿勢を使用するときに、ソース モデルが物理オブジェクトと一致しないのはなぜですか?**

**A:** Unity では、オブジェクト モデルのインポート時に座標系が変更されることがあります。 たとえば、Object Anchors Unity SDK では座標系を右手系から左手系に変換するときに Z 軸が反転されますが、Unity では X 軸、Y 軸いずれかに関して追加の回転が適用される可能性があります。 開発者は、座標系を視覚化して比較することで、この追加の回転を判断できます。

**Q: 2D はサポートされていますか?**

**A:** ジオメトリ ベースであるため、3D のみがサポートされています。

**Q: 色の異なる同じモデルを区別することは可能ですか?**

**A:** 使用されるアルゴリズムはジオメトリ ベースであるため、色違いの同じモデルで検出時の動作が変化することはありません。

**Q: インターネット接続なしで Object Anchors を使用することはできますか?**

**A:**
* モデルの変換とトレーニングはクラウド内で行われるため、これらについては接続が必要です。
* ランタイム セッションは完全にデバイス上で実行され、すべての計算が HoloLens 2 で行われるため、接続は必要ありません。

## <a name="privacy-faq"></a>プライバシーに関する FAQ
**Q: Azure Object Anchors ではどのようにデータが保存されますか?**

**A:** Microsoft によって保存されるのはシステム メタデータのみです。それは Microsoft マネージド データ暗号化キーを使用して保存時に暗号化されます。

## <a name="next-steps"></a>次のステップ

この記事では、Azure Object Anchors を使用する際に最適な結果を得るための一般的な質問に対する回答について学びました。
関連記事を次に示します。

> [!div class="nextstepaction"]
> [ベスト プラクティス](./best-practices.md)

> [!div class="nextstepaction"]
> [オブジェクト検出のトラブルシューティング](./troubleshoot/object-detection.md)
