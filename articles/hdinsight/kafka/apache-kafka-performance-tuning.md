---
title: Apache Kafka HDInsight クラスターのパフォーマンスの最適化
description: Azure HDInsight 上で Apache Kafka のワークロードを最適化するための手法の概要を示します。
ms.service: hdinsight
ms.topic: conceptual
ms.date: 12/19/2019
ms.openlocfilehash: b5c149499fe21940e58c795dbed2407c046ac43d
ms.sourcegitcommit: 91915e57ee9b42a76659f6ab78916ccba517e0a5
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 10/15/2021
ms.locfileid: "130044423"
---
# <a name="performance-optimization-for-apache-kafka-hdinsight-clusters"></a>Apache Kafka HDInsight クラスターのパフォーマンスの最適化

この記事では、HDInsight で Apache Kafka のワークロードのパフォーマンスを最適化するためのいくつかの提案を示します。 プロデューサーとブローカーの構成の調整に焦点を当てています。 パフォーマンスを測定するさまざまな方法があり、適用する最適化はビジネス ニーズによって異なります。

## <a name="architecture-overview"></a>アーキテクチャの概要

Kafka トピックを使用して、レコードを整理します。 レコードは、プロデューサーによって生成され、コンシューマーによって消費されます。 プロデューサーは Kafka ブローカーにレコードを送信し、それからデータが格納されます。 HDInsight クラスターの各ワーカー ノードが、Kafka のブローカーです。

トピックは、ブローカー間でレコードを分割します。 レコードの使用時に、パーティションあたり最大 1 つのコンシューマーを使用して、データの並列処理を実現できます。

レプリケーションを使用して、ノード間でパーティションを複製します。 これにより、ノード (ブローカー) が停止しても保護されます。 レプリカのグループ間で、1 つのパーティションがパーティション リーダーとして指定されます。 プロデューサー トラフィックは、ZooKeeper によって管理された状態に基づいて、各ノードのリーダーにルーティングされます。

## <a name="identify-your-scenario"></a>シナリオの特定

Apache Kafka のパフォーマンスには、スループットと待ち時間という 2 つの主要な側面があります。 スループットとは、アプリでデータを処理できる最大速度のことです。 通常はスループットが高ければそれだけ良好です。 待ち時間とは、データの格納または取得にかかる時間のことです。 通常は待ち時間が短ければそれだけ良好です。 スループット、待ち時間、およびアプリケーションのインフラストラクチャのコストの間での適切なバランスを見つけることは、困難な場合があります。 高スループット、短い待ち時間、またはその両方が必要かどうかに基づいて、パフォーマンス要件はたいてい次の 3 つ一般的な状況の 1 つが当てはまります。

* 高スループット、低待ち時間。 このシナリオでは、高スループットと低待ち時間 (最大 100 ミリ秒) の両方が必要です。 このタイプのアプリケーションは、たとえばサービス可用性監視です。
* 高スループット、高待ち時間。 このシナリオでは、高スループット (最大 1.5 GBps) が必要ですが、長い待ち時間 (250 ミリ秒未満) を許容できます。 このタイプのアプリケーションの例としては、セキュリティや侵入検出アプリケーションなどのほぼリアルタイム プロセスのテレメトリ データ インジェストがあります。
* 低スループット、低待ち時間。 このシナリオでは、リアルタイム処理に対して低待ち時間 (10 ミリ秒未満) が必要ですが、低スループットを許容できます。 このタイプのアプリケーションの例としては、オンラインのスペル チェックと文法チェックがあります。

## <a name="producer-configurations"></a>プロデューサーの構成

次のセクションでは、Kafka プロデューサーのパフォーマンスを最適化するために、最も重要な構成プロパティの一部を強調表示します。 すべての構成プロパティの詳細な説明については、[プロデューサーの構成に関する Apache Kafka のドキュメント](https://kafka.apache.org/documentation/#producerconfigs)を参照してください。

### <a name="batch-size"></a>バッチ サイズ

Apache Kafka のプロデューサーは、単一のストレージ パーティションに格納される 1 単位として送信される、メッセージのグループ (バッチと呼ばれる) をアセンブルします。 バッチ サイズは、そのグループを送信する前になければならないバイト数を意味します。 `batch.size` パラメーターを増やすと、ネットワークと IO 要求からのオーバーヘッドの処理が減るため、スループットを向上させることができます。 負荷が低く、バッチ サイズが大きくなると、プロデューサーはバッチの準備が完了するのを待機するため、Kafka の送信待ち時間が増える可能性があります。 負荷が高い場合は、スループットを向上させて待ち時間を減らすために、バッチ サイズを増やすことをお勧めします。

### <a name="producer-required-acknowledgments"></a>プロデューサーが必要な確認

プロデューサーが必要な `acks` 構成では、書き込み要求が完了したと見なされる前に、パーティション リーダーによって要求される確認の数を判別します。 この設定はデータの信頼性に影響し、`0`、`1`、または`-1` の値を取ります。 値 `-1` は、書き込みが完了する前に、確認をすべてのレプリカから受け取る必要があることを意味します。 `acks = -1` を設定すると、データ損失に対する保証は高くなりますが、待ち時間が長くなりスループットが低下することにもなります。 アプリケーションの要件によりさらに高いスループットが求められる場合は、`acks = 0` または `acks = 1` の設定を試みてください。 一部のレプリカを確認しないと、データの信頼性が低くなる可能性があることに留意してください。

### <a name="compression"></a>[圧縮]

Kafka プロデューサーは、メッセージをブローカーに送信する前に圧縮するように構成できます。 `compression.type` 設定は、使用する圧縮コーデックを指定します。 サポートされている圧縮コーデックは、「gzip」、「snappy」、「lz4」です。 圧縮には利点があり、ディスク容量の制限がある場合には考慮する必要があります。

2 つの一般的に使用される圧縮コーデック `gzip` と `snappy` で、`gzip` のほうが圧縮率が高いため、CPU 負荷は高くなりますがディスク使用量は少なくなります。 `snappy` コーデックは圧縮率は低く、CPU のオーバーヘッドは少なくて済みます。 ブローカーのディスクまたはプロデューサーの CPU の制限事項に基づいて、使用するコーデックを決定できます。 `gzip` は `snappy` に比べて、5 倍の速度でデータを圧縮できます。

データ圧縮を使用すると、ディスクに格納できるレコードの数が増加します。 プロデューサーとブローカーによって使用されている圧縮形式の間で不一致がある場合には、CPU のオーバーヘッドが増える可能性もあります。 データは送信する前に圧縮し、処理する前に圧縮を解除する必要があります。

## <a name="broker-settings"></a>ブローカー設定

次のセクションでは、Kafka ブローカーのパフォーマンスを最適化するための、いくつかの最も重要な設定を強調表示します。 すべてのブローカーの設定の詳細な説明については、[Apache Kafka ドキュメントのブローカー構成](https://kafka.apache.org/documentation/#brokerconfigs)に関するページを参照してください。

### <a name="number-of-disks"></a>ディスクの数

ストレージ ディスクの IOPS (1 秒あたりの入出力操作) および 1 秒あたりの読み取り/書き込みバイト数が限られています。 新しいパーティションを作成する際に、Kafka は、使用可能なディスク間で負荷を分散するために、既存のパーティションが最も少ないディスクに新しい各パーティションを格納します。 ストレージ戦略にも関わらず、各ディスク上で何百ものパーティションのレプリカを処理するときに、Kafka は使用可能なディスク スループットを容易に飽和させてしまう可能性があります。 ここでのトレードオフは、スループットとコストでの間のものです。 アプリケーションがより高いスループットを必要とする場合は、ブローカーごとにより多くのマネージド ディスクを持つクラスターを作成します。 HDInsight では、実行中のクラスターへのマネージド ディスクの追加は現在サポートしていません。 マネージド ディスクの数を構成する方法の詳細については、「[HDInsight 上の Apache Kafka 用に記憶域とスケーラビリティを構成する](apache-kafka-scalability.md)」を参照してください。 クラスター内のノードのストレージ スペースを増やすことでコストがどのような影響を受けるかを理解します。

### <a name="number-of-topics-and-partitions"></a>トピックとパーティションの数。

Kafka のプロデューサーは、トピックに書き込みます。 Kafka のコンシューマーは、トピックから読み取ります。 トピックは、ディスク上のデータ構造であるログに関連付けられます。 Kafka は、プロデューサーからのレコードをトピック ログの末尾に追加します。 トピック ログは、複数ファイルに分散する多数のパーティションで構成されます。 これらのファイルは、同様に、複数の Kafka クラスター ノードに分散します。 コンシューマーは各自の間隔で Kafka トピックから読み取り、トピック ログ内で位置 (オフセット) を選択できます。

Kafka の各パーティションはシステム上のログ ファイルであり、プロデューサー スレッドは同時に複数のログに書き込むことができます。 同様に、各コンシューマー スレッドはメッセージを 1 つのパーティションから読み取るので、複数のパーティションからの使用が並列で処理されます。

パーティション密度 (ブローカーごとのパーティションの数) を増やすことで、メタデータ操作に関連し、パーティションのリーダーとそのフォロワーの間のパーティション要求/応答ごとのオーバーヘッドが追加されます。 まだ流れるデータがない場合であっても、パーティションのレプリカは引き続きリーダーからデータをフェッチします。これによりネットワーク経由での要求の送受信のための追加の処理が発生します。

HDInsight の Apache Kafka クラスター 1.1 以上では、レプリカを含め、ブローカーごとに最大 1,000 個のパーティションを持つことをお勧めします。 ブローカーごとのパーティションの数を増やすと、スループットが低下し、トピックが使用不可になる場合もあります。 Kafka パーティションのサポートの詳細については、[バージョン 1.1.0 でサポートされるパーティションの数の増加に関する公式の Apache Kafka ブログの投稿](https://blogs.apache.org/kafka/entry/apache-kafka-supports-more-partitions)を参照してください。 トピックの変更の詳細については、「[Apache Kafka: modifying topics](https://kafka.apache.org/documentation/#basic_ops_modify_topic)」(Apache Kafka: トピックを変更する) を参照してください。

### <a name="number-of-replicas"></a>レプリカの数

高いレプリケーション係数により、パーティションのリーダーとフォロワーの間で追加の要求が発生します。 結果として、高いレプリケーション係数によりさらに多くのディスクと CPU が追加の要求の処理に使用されるため、書き込みの待ち時間は長くなりスループットは低下します。

Azure HDInsight では、Kafka には、少なくとも 3 倍のレプリケーションを使用することをお勧めします。 ほとんどの Azure リージョンは 3 つの障害ドメインがありますが、2 つの障害ドメインしかないリージョンでは、ユーザーは 4 倍のレプリケーションを使用する必要があります。

レプリケーションの詳細については、「[Apache Kafka: レプリケーション](https://kafka.apache.org/documentation/#replication)」と「[Apache Kafka: レプリケーション係数を増やす](https://kafka.apache.org/documentation/#basic_ops_increase_replication_factor)」を参照してください。

## <a name="next-steps"></a>次のステップ

* [Azure で Apache Kafka を使用して 1 日あたり数十億個のイベントを処理する](https://azure.microsoft.com/blog/processing-trillions-of-events-per-day-with-apache-kafka-on-azure/)
* [HDInsight での Apache Kafka とは](apache-kafka-introduction.md)
