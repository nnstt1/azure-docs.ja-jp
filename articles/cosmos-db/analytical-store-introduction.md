---
title: Azure Cosmos DB 分析ストアとは
description: Azure Cosmos DB のトランザクション (行ベース) ストアと分析 (列ベース) ストアについて説明します。 分析ストアの利点、大規模なワークロードのパフォーマンスへの影響、トランザクション ストアから分析ストアへのデータの自動同期などです
author: Rodrigossz
ms.service: cosmos-db
ms.topic: conceptual
ms.date: 11/02/2021
ms.author: rosouz
ms.custom: seo-nov-2020
ms.openlocfilehash: 712b1d3e7fde41991f9cea2d62e7e0864224509d
ms.sourcegitcommit: 838413a8fc8cd53581973472b7832d87c58e3d5f
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/10/2021
ms.locfileid: "132135204"
---
# <a name="what-is-azure-cosmos-db-analytical-store"></a>Azure Cosmos DB 分析ストアとは
[!INCLUDE[appliesto-sql-mongodb-api](includes/appliesto-sql-mongodb-api.md)]

Azure Cosmos DB の分析ストアは、トランザクション ワークロードに影響を与えることなく、Azure Cosmos DB 内の運用データに対する大規模な分析を可能にするための、完全に分離された列ストアです。 

Azure Cosmos DB のトランザクション ストアはスキーマに依存せず、スキーマやインデックスを管理する必要なしに、アプリケーション上で反復処理を実行できます。 これに対し、Azure Cosmos DB の分析ストアは、分析クエリのパフォーマンスを最適化するためにスキーマ化されています。 この記事では、分析ストレージについて詳しく説明します。

## <a name="challenges-with-large-scale-analytics-on-operational-data"></a>運用データでの大規模な分析に関する課題

Azure Cosmos DB コンテナー内のマルチモデルの運用データは、インデックス付きの行ベースの "トランザクション ストア" に内部的に格納されます。 行ストアの形式は、ミリ秒単位の応答時間での高速なトランザクションの読み取りと書き込み、および操作クエリで実行できるように、設計されています。 ご利用のデータセットのサイズが大きくなると、この形式で格納されているデータに対する複雑な分析クエリでは、プロビジョニングされたスループットに関するコストが高くなる可能性があります。 プロビジョニングされたスループットが大量に消費されると、リアルタイムのアプリケーションやサービスによって使用されるトランザクション ワークロードのパフォーマンスに影響します。

従来は、大量のデータを分析するには、オペレーショナル データが Azure Cosmos DB のトランザクション ストアから抽出されて、別のデータ レイヤーに格納されます。 たとえば、データは適切な形式のデータ ウェアハウスやデータ レイクに格納されます。 その後、このデータは大規模な分析に使用され、Apache Spark クラスターなどのコンピューティング エンジンを使用して分析されます。 このようにオペレーショナル データから分析ストレージとコンピューティング レイヤーを分離すると、トランザクションワークロードに影響する可能性を最小限に抑えるために ETL (抽出、変換、読み込み) パイプラインの実行頻度が低くなるため、待機時間が長くなります。

また、オペレーショナル データの更新を処理する場合は、新しく取り込まれたオペレーショナル データだけを処理する場合と比較して、ETL パイプラインも複雑になります。 

## <a name="column-oriented-analytical-store"></a>列指向の分析ストア

Azure Cosmos DB の分析ストアでは、従来の ETL パイプラインで発生する複雑さと待機時間の問題が対処されています。 Azure Cosmos DB の分析ストアでは、オペレーショナル データを別の列ストアに自動的に同期させることができます。 列ストアの形式は、最適化された方法で実行される大規模な分析クエリに適しているため、このようなクエリの待機時間が向上します。

Azure Synapse Link を使用すると、Azure Synapse Analytics から Azure Cosmos DB の分析ストアに直接リンクすることで、ETL なしの HTAP ソリューションを構築できます。 これにより、オペレーショナル データに対してほぼリアルタイムの大規模な分析を実行できます。

## <a name="features-of-analytical-store"></a>分析ストアの機能 

Azure Cosmos DB コンテナーで分析ストアを有効にすると、コンテナー内のオペレーショナル データに基づいて、新しい列ストアが内部的に作成されます。 この列ストアは、そのコンテナーに対する行指向のトランザクション ストアとは別に保持されます。 オペレーショナル データに対する挿入、更新、削除は、分析ストアに自動的に同期されます。 データを同期するために変更フィードや ETL は必要ありません。

## <a name="column-store-for-analytical-workloads-on-operational-data"></a>オペレーショナル データに対する分析ワークロードでの列ストア

通常、分析ワークロードには、選択したフィールドの集計と順次スキャンが含まれます。 分析ストアでは、データを列優先の順序で格納することにより、各フィールドの値のグループをまとめてシリアル化することができます。 この形式を使用すると、特定のフィールドのスキャンまたは統計計算に必要な IOPS が減少します。 大きなデータ セットに対するスキャンのクエリ応答時間が大幅に向上します。 

たとえば、オペレーショナル テーブルが次のような形式になっているとします。

:::image type="content" source="./media/analytical-store-introduction/sample-operational-data-table.png" alt-text="オペレーショナル テーブルの例" border="false":::

行ストアでは、上記のデータが、行ごとにシリアル化された形式で、ディスクに保持されます。 この形式を使用すると、トランザクションの読み取り、書き込み、操作クエリ ("Product1 に関する情報の取得" など) を高速化できます。 ただし、データセットが大きくなるため、データに対して複雑な分析クエリを実行する場合は、コストが高くなる可能性があります。 たとえば、"異なる事業単位と月についての、'機材' というカテゴリに属する製品の売上動向" を取得するには、複雑なクエリを実行する必要があります。 このデータセットの大規模なスキャンでは、プロビジョニングされたスループットに関して高コストになる可能性があり、リアルタイムのアプリケーションやサービスに利用されるトランザクション ワークロードのパフォーマンスにも影響する場合があります。

列ストアである分析ストアは、類似したデータのフィールドがまとめてシリアル化され、ディスクの IOPS が減るため、そのようなクエリに適しています。

次の図では、Azure Cosmos DB でのトランザクション行ストアと分析列ストアの比較を示します。

:::image type="content" source="./media/analytical-store-introduction/transactional-analytical-data-stores.png" alt-text="Azure Cosmos DB でのトランザクション行ストアと分析列ストアの比較" border="false":::

## <a name="decoupled-performance-for-analytical-workloads"></a>分析ワークロードの分離されたパフォーマンス

分析ストアはトランザクション ストアとは別のものであるため、分析クエリが原因でトランザクション ワークロードのパフォーマンスが影響を受けることはありません。  要求ユニット (RU) を分析ストアのために別に割り当てる必要はありません。

## <a name="auto-sync"></a>自動同期

自動同期とは、Azure Cosmos DB の完全に管理された機能のことであり、オペレーショナル データの挿入、更新、削除が、ほぼリアルタイムでトランザクション ストアから分析ストアに自動的に同期されます。 自動同期の待機時間は通常 2 分以内です。 コンテナーを多数備えた共有スループット データベースの場合は、個々のコンテナーの自動同期の待機時間が長くなり、最大で 5 分かかる可能性があります。 この待機時間がお客様のシナリオにどのように適合するかについて、詳細を把握したいと考えています。 そのため、[Azure Cosmos DB チーム](mailto:cosmosdbsynapselink@microsoft.com)までご連絡ください。

自動同期プロセスの各実行の終了時に、トランザクション データがすぐに Azure Synapse Analytics ランタイムで使用できるようになります。

* Azure Synapse Analytics Spark プールは、自動的に更新される Spark テーブルを通じて、または常にデータの最後の状態を読み取る `spark.read` コマンドを介して、最新の更新を含むすべてのデータを読み取ることができます。

*  Azure Synapse Analytics SQL サーバーレス プールは、自動的に更新されるビューを通じて、または常にデータの最新の状態を読み取る ` OPENROWSET` コマンドと一緒に `SELECT` を介して、最新の更新を含むすべてのデータを読み取ることができます。

> [!NOTE]
> トランザクション データは、トランザクション TTL が 2 分より短い場合でも、分析ストアと同期されます。 

## <a name="scalability--elasticity"></a>スケーラビリティと弾力性

行方向のパーティション分割を使用することにより、Azure Cosmos DB のトランザクション ストアでは、ダウンタイムなしで、ストレージとスループットを弾力的にスケーリングできます。 トランザクション ストアでの行方向のパーティション分割を使うと、自動同期のスケーラビリティと弾力性が提供され、データがほぼリアルタイムで分析ストアに同期されます。 データの同期は、トランザクション トラフィックのスループットが 1000 操作/秒または 100 万操作/秒のいずれであっても行われ、トランザクション ストアにプロビジョニングされたスループットには影響しません。 

## <a name="automatically-handle-schema-updates"></a><a id="analytical-schema"></a>スキーマの更新を自動的に処理する

Azure Cosmos DB のトランザクション ストアはスキーマに依存せず、スキーマやインデックスを管理する必要なしに、アプリケーション上で反復処理を実行できます。 これに対し、Azure Cosmos DB の分析ストアは、分析クエリのパフォーマンスを最適化するためにスキーマ化されています。 Azure Cosmos DB では、自動同期機能により、トランザクション ストアからの最新の更新に対するスキーマの推論が管理されます。 また、入れ子になったデータ型の処理を含む、すぐに使用できる分析ストアのスキーマ表現も管理されます。

スキーマが進化し、新しいプロパティが時間と共に追加されると、分析ストアにより、トランザクション ストア内のすべての履歴スキーマに対して、統合されたスキーマが自動的に提供されます。

> [!NOTE]
> 分析ストアのコンテキストでは、次の構造がプロパティと見なされます。
> * JSON の "要素" または "`:` で区切られた文字列/値のペア"。
> * `{` と `}` で区切られた JSON オブジェクト。
> * `[` と `]` で区切られた JSON 配列。


### <a name="schema-constraints"></a>スキーマの制約

次の制約は、分析ストアでスキーマを自動的に推論して正しく表すことができるようにするときに、Azure Cosmos DB 内のオペレーショナル データに適用されます。

* スキーマの各入れ子レベルでの最大プロパティ数は 1,000 個であり、入れ子の深さの最大値は 127 です。
  * 分析ストアでは、最初の 1,000 個のプロパティのみが表示されます。
  * 分析ストアでは、最初の 127 個の入れ子のレベルのみが表示されます。
  * JSON ドキュメントの最初のレベルは、その `/` ルート レベルです。
  * ドキュメントの最初のレベルのプロパティは、列として表示されます。


* サンプル シナリオ: 
  * ドキュメントの最初のレベルに 2,000 個のプロパティがある場合は、最初の 1,000 個のみが表示されます。
  * ドキュメントに 5 つのレベルがあり、それぞれ 200 個のプロパティが含まれる場合は、すべてのプロパティが表示されます。
  * ドキュメントに 10 のレベルがあり、各レベルに 400 個のプロパティが含まれる場合、分析ストアに完全に表示されるのは最初の 2 レベルのみです。 3 番目のレベルについては半分が表示されます。

* 以下の架空のドキュメントには、4 個のプロパティと 3 つのレベルが含まれています。
  * レベルは `root` と `myArray` で、`myArray` 内では入れ子構造になっています。
  * プロパティは `id`、`myArray`、`myArray.nested1`、`myArray.nested2` です。
  * 分析ストア表現には、`id` と `myArray` の 2 つの列があります。 Spark または T-SQL 関数を使用して、入れ子構造を列として公開することもできます。


```json
{
  "id": "1",
  "myArray": [
    "string1",
    "string2",
    {
      "nested1": "abc",
      "nested2": "cde"
    }
  ]
}
```

* JSON ドキュメント (および Cosmos DB コレクション/コンテナー) では一意性の観点から大文字と小文字が区別されますが、分析ストアでは区別されません。

  * **同じドキュメント内:** 大文字と小文字の区別を比較する場合、同じレベルのプロパティ名は一意である必要があります。 たとえば、次の JSON ドキュメントでは、同じレベルで "Name" と "name" が使用されています。 これは有効な JSON ドキュメントですが、一意性制約を満たしていないため、分析ストアでは、完全に表示されません。 この例で "Name" と "name" は、大文字と小文字を区別せずに比べると同じになっています。 最初に出現する `"Name": "fred"` のみが、分析ストアで表示されます。 `"name": "john"` はまったく表示されません。
  
  
  ```json
  {"id": 1, "Name": "fred", "name": "john"}
  ```
  
  * **異なるドキュメント内:** 同じレベルでプロパティと名前が同じでも、大文字と小文字が異なっていれば、最初に出現した名前の形式を使用して同じ列内に表示されます。 たとえば、次の JSON ドキュメントでは、`"Name"` と `"name"` が同じレベルにあります。 最初のドキュメント形式は `"Name"` であるため、これが分析ストアでプロパティ名を表すために使用されます。 言い換えると、分析ストアの列名は `"Name"` になります。 `"fred"` と `"john"` の両方が `"Name"` 列に表示されます。


  ```json
  {"id": 1, "Name": "fred"}
  {"id": 2, "name": "john"}
  ```


* コレクション内の最初のドキュメントによって、最初の分析ストア スキーマが定義されます。
  * 最初のスキーマよりも多くのプロパティを持つドキュメントでは、分析ストアに新しい列が生成されます。
  * 列を削除することはできません。
  * コレクション内のすべてのドキュメントを削除しても、分析ストア スキーマはリセットされません。
  * スキーマのバージョン管理はありません。 トランザクション ストアから推定された最新のバージョンが、分析ストアに表示されます。

* 現時点では、Azure Synapse Spark では、次に示す特殊文字が名前に含まれているプロパティを読み取ることはできません。 Azure Synapse SQL サーバーレスは影響を受けません。
  * : (コロン)
  * ` (グレーブ アクセント)
  * , (コンマ)
  * ; (セミコロン)
  * {}
  * ()
  * \n
  * \t
  * = (等号)
  * " (引用符)
 
* 上に示した文字を使用するプロパティ名がある場合は、次のような選択肢があります。
   * データ モデルを事前に変更して、これらの文字を回避します。
   * 現在、スキーマのリセットはサポートされていないため、アプリケーションを変更して、類似した名前の冗長プロパティを追加することで、これらの文字を回避できます。
   * 変更フィードを使用して、プロパティ名にこれらの文字を含まないコンテナーの具体化されたビューを作成します。
   * 新しい `dropColumn` Spark オプションを使用して、データフレームにデータを読み込むときに影響を受ける列を無視します。 コンマを含む "FirstName, LastNAme" という名前の仮定の列を削除するための構文は次のとおりです。

```Python
df = spark.read\
     .format("cosmos.olap")\
     .option("spark.synapse.linkedService","<your-linked-service-name>")\
     .option("spark.synapse.container","<your-container-name>")\
     .option("spark.synapse.dropColumn","FirstName,LastName")\
     .load()
```

* Azure Synapse Spark では、名前に空白を含むプロパティがサポートされるようになりました。

* 次の BSON データ型はサポートされておらず、分析ストアでは表されません。
  * Decimal128
  * Regular Expression
  * DB Pointer
  * JavaScript
  * シンボル
  * MinKey / MaxKey 

* ISO 8601 UTC 標準に準拠した DateTime 文字列を使用する場合、次の動作を期待できます。
  * Azure Synapse の Spark プールは、これらの列を `string` として表示します。
  * Azure Synapse の SQL サーバーレス プールは、これらの列を `varchar(8000)` として表示します。

* Azure Synapse の SQL サーバーレス プールでは、最大 1,000 列の結果セットがサポートされており、入れ子になった列を公開する場合も、その制限までカウントされます。 データ アーキテクチャを設計し、トランザクション データをモデル化する場合は、この情報を考慮してください。


### <a name="schema-representation"></a>スキーマ表現

分析ストアには 2 種類のスキーマ表現があります。 これらの種類では、データベース アカウント内のすべてのコンテナーのスキーマ表現方法を定義していますが、クエリ エクスペリエンスのシンプルさと、ポリモーフィック型スキーマでのより包括的な列表現の利便性の間にはトレードオフがあります。

* SQL (CORE) API アカウントの既定のオプションである、適切に定義されたスキーマ表現。 
* MongoDB 用 Azure Cosmos DB API アカウントの既定のオプションである、完全に忠実なスキーマ表現。

#### <a name="full-fidelity-schema-for-sql-api-accounts"></a>SQL API アカウントの完全に忠実なスキーマ

Cosmos DB アカウントで Synapse Link を初めて有効にするときにスキーマの種類を設定することによって、既定のオプションではなく、SQL (コア) API アカウントの完全に忠実なスキーマを使用できます。 既定のスキーマ表現の種類を変更することに関する考慮事項を次に示します。

 * このオプションは、Synapse Link がまだ有効になって **いない** アカウントでのみ有効です。
 * スキーマ表現の種類を、適切に定義されたスキーマから完全に忠実なスキーマに、あるいはその逆に再設定することはできません。
 * 現在、MongoDB 用 Azure Cosmos DB API アカウントは、スキーマ表現の変更のこの可能性と互換性がありません。 すべての MongoDB アカウントには常に、完全に忠実なスキーマ表現の種類があります。
 * 現在、Azure portal からこの変更を行うことはできません。 Azure portal で Synapse Link が有効になっているすべてのデータベース アカウントには、既定のスキーマ表現の種類である、適切に定義されたスキーマがあります。
 
スキーマ表現の種類の決定は、Azure CLI または PowerShell を使用して、そのアカウントで Synapse Link を有効にするのと同時に行う必要があります。
 
 Azure CLI を使用する場合:
 ```cli
 az cosmosdb create --name MyCosmosDBDatabaseAccount --resource-group MyResourceGroup --subscription MySubscription --analytical-storage-schema-type "FullFidelity" --enable-analytical-storage true
 ```
 
> [!NOTE]
> 既存のアカウントの場合は、上のコマンドで `create` を `update` に置き換えます。
 
  PowerShell を使用する場合:
  ```
   New-AzCosmosDBAccount -ResourceGroupName MyResourceGroup -Name MyCosmosDBDatabaseAccount  -EnableAnalyticalStorage true -AnalyticalStorageSchemaType "FullFidelity"
   ```
 
> [!NOTE]
> 既存のアカウントの場合は、上のコマンドで `New-AzCosmosDBAccount` を `Update-AzCosmosDBAccount` に置き換えます。
 


#### <a name="well-defined-schema-representation"></a>適切に定義されたスキーマ表現

適切に定義されたスキーマ表現は、スキーマに依存しないデータの単純な表形式表現をトランザクション ストアに作成します。 適切に定義されたスキーマ表現には、次の考慮事項があります。

* 最初のドキュメントで基本スキーマを定義し、プロパティはすべてのドキュメントで常に同じ型である必要があります。 例外は次の場合だけです。
  * null からそれ以外のデータ型。最初に出現する null 以外の型で、列のデータ型が定義されます。 null 以外の最初のデータ型に従っていないドキュメントは、分析ストアでは表されません。
  * `float` から `integer`。 すべてのドキュメントが分析ストアで表されます。
  * `integer` から `float`。 すべてのドキュメントが分析ストアで表されます。 ただし、Azure Synapse SQL サーバーレス プールでこのデータを読み取るには、WITH 句を使用して列を `varchar` に変換する必要があります。 この最初の変換の後で、再び数値に変換することができます。 次の例を確認してください。ここで、**num** の最初の値は整数で、2 番目の値は float でした。

```SQL
SELECT CAST (num as float) as num
FROM OPENROWSET(PROVIDER = 'CosmosDB',
                CONNECTION = '<your-connection',
                OBJECT = 'IntToFloat',
                SERVER_CREDENTIAL = 'your-credential'
) 
WITH (num varchar(100)) AS [IntToFloat]
```

  * 基本スキーマのデータ型に従わないプロパティは、分析ストアでは表されません。 たとえば、次の 2 つのドキュメントについて考えてみます。最初のものでは、分析ストアの基本スキーマが定義されています。 `id` が `2` である 2 番目のドキュメントは、プロパティ `"a"` が文字列であり、最初のドキュメントの`"a"` は数値であるため、2 番目には適切に定義されたスキーマはありません。 この場合、コンテナーの有効期間をとおして、分析ストアでは `"a"` のデータ型は `integer` として登録されます。 2 番目のドキュメントはそれでも分析ストアに含まれますが、その `"a"` プロパティは含まれません。
  
    * `{"id": "1", "a":123}` 
    * `{"id": "2", "a": "str"}`
     
 > [!NOTE]
 > 上のこの条件は、null プロパティには適用されません。 たとえば、`{"a":123} and {"a":null}` はやはり適切に定義されています。

* 配列型に含まれる繰り返される型は、1 つである必要があります。 たとえば、`{"a": ["str",12]}` は、配列には整数型と文字列型が混在しているため、適切に定義されたスキーマではありません。

> [!NOTE]
> Azure Cosmos DB 分析ストアが適切に定義されたスキーマ表現に準拠していて、上記の仕様を特定の項目が違反している場合、これらの項目は分析ストアには含まれません。

* 適切に定義されたスキーマのさまざまな型に関しては、異なる動作を想定しています。
  * Azure Synapse の Spark プールは、これらの値を `undefined` として表示します。
  * Azure Synapse の SQL サーバーレス プールは、これらの値を `NULL` として表示します。

* 明示的な `null` 値に関しては、異なる動作を想定しています。
  * Azure Synapse の Spark プールは、これらの値を `0` (ゼロ) として読み取ります。 そしてこれは、列の値が null 以外になるとすぐに `undefined` に変更されます。
  * Azure Synapse の SQL サーバーレス プールは、これらの値を `NULL` として読み取ります。
    
* 存在しない列に関しては、異なる動作を想定しています。
  * Azure Synapse の Spark プールは、これらの列を `undefined` として表示します。
  * Azure Synapse の SQL サーバーレス プールは、これらの列を `NULL` として表示します。


#### <a name="full-fidelity-schema-representation"></a>完全に忠実なスキーマ表現

完全に忠実なスキーマ表現は、スキーマに依存しないオペレーショナル データ内のさまざまなポリモーフィック型スキーマを処理するように設計されています。 このスキーマ表現では、適切に定義されたスキーマ制約 (つまり、混在したデータ型フィールドも、混在したデータ型配列も存在しない) に違反しても、分析ストアから項目が削除されることはありません。

これを実現するには、オペレーショナル データのリーフ プロパティを分析ストアに変換して、個別の列をプロパティの値のデータ型に基づかせます。 リーフ プロパティ名は、明確にクエリを実行できるように、分析ストア スキーマでデータ型をサフィックスに使用して拡張されます。

完全に忠実なスキーマ表現では、そのデータ型の列が、各プロパティの各データ型によって生成されます。 それぞれが 最大 1,000 個のプロパティの 1 つとしてカウントされます。

たとえば、トランザクション ストアで次のサンプル ドキュメントを見てみましょう。

```json
{
name: "John Doe",
age: 32,
profession: "Doctor",
address: {
  streetNo: 15850,
  streetName: "NE 40th St.",
  zip: 98052
},
salary: 1000000
}
```

入れ子になったオブジェクト `address` 内のリーフ プロパティ `streetNo` は、分析ストア スキーマで列 `address.object.streetNo.int32` として表されます。 データ型は、サフィックスとして列に追加されます。 このように、リーフ プロパティ `streetNo` の値が "123" (文字列であることに注意してください) であるトランザクション ストアに、別のドキュメントが追加された場合、以前に書き込まれた列の型を変更することなく、分析ストアのスキーマが自動的に進化します。 "123" のこの値が格納されている `address.object.streetNo.string` として分析ストアに追加された新しい列。

**データ型とサフィックスのマップ**

次に示すのは、分析ストア内のすべてのプロパティ データ型とそのサフィックス表現のマップです。

|元のデータ型  |サフィックス  |例  |
|---------|---------|---------|
| Double |  ".float64" |    24.99|
| Array | ".array" |    ["a", "b"]|
|Binary | ".binary" |0|
|Boolean    | ".bool"   |True|
|Int32  | ".int32"  |123|
|Int64  | ".int64"  |255486129307|
|[Null]   | ".null"   | null|
|String|    ".string" | "ABC"|
|Timestamp |    ".timestamp" |  Timestamp(0, 0)|
|DateTime   |".date"    | ISODate("2020-08-21T07:43:07.375Z")|
|ObjectId   |".objectId"    | ObjectId("5f3f7b59330ec25c132623a2")|
|ドキュメント   |".object" |    {"a": "a"}|

* 明示的な `null` 値に関しては、異なる動作を想定しています。
  * Azure Synapse の Spark プールは、これらの値を `0` (ゼロ) として読み取ります。
  * Azure Synapse の SQL サーバーレス プールは、これらの値を `NULL` として読み取ります。
  
* 存在しない列に関しては、異なる動作を想定しています。
  * Azure Synapse の Spark プールは、これらの列を `undefined` として表示します。
  * Azure Synapse の SQL サーバーレス プールは、これらの列を `NULL` として表示します。

## <a name="cost-effective-archival-of-historical-data"></a>履歴データのコスト効率に優れたアーカイブ

データの階層化とは、異なるシナリオ用に最適化されたストレージ インフラストラクチャ間にデータを分離することです。 これにより、エンドツーエンドのデータ スタックの全体的なパフォーマンスとコスト効果が向上します。 分析ストアにより、Azure Cosmos DB では、トランザクション ストアから分析ストアへの異なるデータ レイアウトでのデータの自動階層化がサポートされるようになりました。 ストレージ コストに関してトランザクション ストアより分析ストアの方が最適化されているため、より長い期間のオペレーショナル データを履歴分析用に保持することができます。

分析ストアを有効にした後は、トランザクション ワークロードのデータ保持ニーズに基づいて、一定期間後にトランザクション ストアからレコードが自動的に削除されるように、"トランザクション ストアの Time to Live (トランザクション TTL)" プロパティを構成できます。 同様に、"分析ストアの Time to Live (分析 TTL)" を使用すると、トランザクション ストアからは独立して、分析ストアに保持されるデータのライフサイクルを管理できます。 分析ストアを有効にし、TTL プロパティを構成することにより、2 つのストアのデータ保持期間をシームレスに階層化し、定義することができます。

> [!NOTE]
>現在、分析ストアではバックアップと復元がサポートされていません。 バックアップ ポリシーを分析ストアに依存して計画することはできません。 詳細については、[こちらの](synapse-link.md#limitations)ドキュメントの制限事項に関するセクションを参照してください。 分析ストア内のデータには、トランザクション ストアに存在するものとは異なるスキーマがあることに注意することが重要です。 RU コストをかけずに分析ストアのデータのスナップショットを生成することはできますが、このスナップショットを使用したトランザクション ストアのバックフィードは保証できません。 このプロセスはサポートされていません。

## <a name="global-distribution"></a>グローバル分散

グローバルに分散された Azure Cosmos DB アカウントがある場合、コンテナーの分析ストアを有効にした後、そのアカウントのすべてのリージョンでそれを使用できるようになります。  オペレーショナル データに対する変更はすべて、すべてのリージョンにグローバルにレプリケートされます。 Azure Cosmos DB のデータの最も近いリージョン コピーに対して、分析クエリを効率的に実行できます。

## <a name="partitioning"></a>パーティション分割

分析ストアのパーティション分割は、トランザクション ストアのパーティション分割にまったく依存しません。 既定では、分析ストア内のデータはパーティション分割されません。 分析クエリに頻繁に使用されるフィルターがある場合は、これらのフィールドに基づいてパーティション分割することで、クエリのパフォーマンスを向上させることができます。 詳細については、[カスタム パーティション分割の概要](custom-partitioning-analytical-store.md)および[カスタム パーティション分割を構成する方法](configure-custom-partitioning.md)に関する記事を参照してください。  

## <a name="security"></a>セキュリティ

* **分析ストアでの認証** は、特定のデータベースに対するトランザクション ストアと同じです。 認証には主キーまたは読み取り専用キーを使用できます。 Synapse Studio のリンクされたサービスを利用して、Azure Cosmos DB のキーが Spark ノートブックに貼り付けられないようにすることができます。 Azure Synapse SQL サーバーレス では、SQL 資格情報を使用して、Azure Cosmos DB キーの SQL ノートブックへの貼り付けを阻止することもできます。 このリンクされたサービスまたはこの資格情報へのアクセスは、ワークスペースにアクセスできるすべてのユーザーが利用できます。

* **プライベート エンドポイントを使用したネットワーク分離** - トランザクション ストアおよび分析ストア内のデータへのネットワーク アクセスを個別に制御できます。 ネットワークの分離は、Azure Synapse ワークスペースのマネージド仮想ネットワーク内で、ストアごとに別個のマネージド プライベート エンドポイントを使用して行われます。 詳細については、[分析ストアのプライベート エンドポイントを構成する](analytical-store-private-endpoints.md)方法に関する記事を参照してください。

* **カスタマー マネージド キーを使用したデータの暗号化** - 同じカスタマー マネージド キーを自動かつ透過的な方法で使用して、トランザクション ストアおよび分析ストア全体のデータをシームレスに暗号化できます。 Azure Synapse Link では、Azure Cosmos DB アカウントのマネージド ID を使用したカスタマー マネージド キーの構成のみがサポートされています。 アカウントで [Azure Synapse Link を有効にする](configure-synapse-link.md#enable-synapse-link)前に、Azure Key Vault のアクセス ポリシーでアカウントのマネージド ID を構成する必要があります。 詳細については、[Azure Cosmos DB アカウントのマネージド ID を使用して、カスタマー マネージド キーを構成](how-to-setup-cmk.md#using-managed-identity)する方法に関するセクションを参照してください。

## <a name="support-for-multiple-azure-synapse-analytics-runtimes"></a>複数の Azure Synapse Analytics ランタイムのサポート

分析ストアは、コンピューティング ランタイムに依存せずに、分析ワークロードに対してスケーラビリティ、弾力性、パフォーマンスを提供するように最適化されています。 ストレージ テクノロジは、手作業を必要とせずに分析ワークロードを最適化するように、自己管理されています。

分析ストレージ システムを分析コンピューティング システムから切り離すことによって、Azure Cosmos DB 分析ストア内のデータのクエリを、Azure Synapse Analytics でサポートされている異なる分析ランタイムから同時に実行できます。 現在、Azure Synapse Analytics では、Apache Spark とサーバーレス SQL プールが Azure Cosmos DB 分析ストアでサポートされています。

> [!NOTE]
> Azure Synapse Analytics のランタイムを使用した分析ストアからの読み取りだけが可能です。 また、その逆も同様で、Azure Synapse Analytics ランタイムは分析ストアからの読み取りだけが可能です。 自動同期プロセスだけが分析ストア内のデータを変更できます。 組み込み Azure Cosmos DB OLTP SDK を使用して、Azure Synapse Analytics Spark プールで Cosmos DB トランザクション ストアにデータを書き戻すことができます。

## <a name="pricing"></a><a id="analytical-store-pricing"></a> 価格

分析ストアは、次の料金が課金される使用量ベースの価格モデルに従います。

* ストレージ: 分析 TTL によって定義されている履歴データを含め、毎月分析ストアに保持されるデータの量。

* 分析の書き込み操作: トランザクション ストアから分析ストアへのオペレーショナル データの更新のフル マネージドの同期 (自動同期)

* 分析の読み取り操作: Azure Synapse Analytics Spark プールおよびサーバーレス SQL プールのランタイムから分析ストアに対して実行された読み取り操作。

分析ストアの価格は、トランザクション ストアの価格モデルとは別のものです。 分析ストアには、プロビジョニングされた RU の概念はありません。 分析ストアの価格モデルの詳細については、[Azure Cosmos DB の価格のページ](https://azure.microsoft.com/pricing/details/cosmos-db/)を参照してください。

分析ストア内のデータにアクセスできるのは、Azure Synapse Link を使用した場合のみです。 これは、Azure Synapse Analytics ランタイムで、Azure Synapse Apache Spark プールと Azure Synapse サーバーレス SQL プールを使用して行われます。 分析ストアのデータへのアクセスの価格モデルの詳細については、[Azure Synapse Analytics の価格のページ](https://azure.microsoft.com/pricing/details/synapse-analytics/)を参照してください。

Azure Cosmos DB コンテナーで分析ストアを有効にするためのだいたいのコストの見積もりを入手するには、分析ストアの観点からは、[Azure Cosmos DB 容量プランナー](https://cosmos.azure.com/capacitycalculator/)を使用して、分析ストレージと書き込み操作のコストを見積もることができます。 分析の読み取り操作のコストは、分析ワークロードの特性によって異なりますが、大まかな見積もりとして、分析ストアの 1 TB のデータをスキャンすると、通常、13 万回の分析読み取り操作が行われ、結果のコストは $0.065 になります。

> [!NOTE]
> 分析ストアの読み取り操作の見積もりは、分析ワークロードの機能であるため、Cosmos DB のコスト計算ツールには含まれません。 上記は、分析ストア内で 1 TB のデータをスキャンするための見積もりですが、フィルターを適用することで、スキャンされるデータの量が少なくなりため、従量課金モデルの場合は、これにより分析読み取り操作の正確な数が判断されます。 分析読み取り操作のより詳細な見積もりは、分析ワークロードに関する概念実証によって提供されます。 この見積もりには、Azure Synapse Analytics のコストは含まれていません。


## <a name="analytical-time-to-live-ttl"></a><a id="analytical-ttl"></a> 分析の Time to Live (TTL)

分析 TTL は、データを分析ストアに保持する必要がある期間を示します (コンテナーの場合)。 

分析ストアが有効になっている場合、オペレーショナル データに対する挿入、更新、削除は、トランザクション TTL の構成に関係なく、トランザクション ストアから分析ストアに自動的に同期されます。 分析ストアへのこのオペレーショナル データの保持は、以下で指定するように、コンテナー レベルの分析 TTL の値によって制御できます。

コンテナーの分析 TTL は、`AnalyticalStoreTimeToLiveInSeconds` プロパティを使用して設定されます。

* 値が "0" に設定されているか、見つからない (または null に設定されている) 場合: 分析ストアは無効になり、トランザクション ストアから分析ストアにデータは複製されません

* 存在し、値が "-1" に設定されている場合: トランザクション ストア内のデータの保持に関係なく、すべての履歴データが分析ストアに保持されます。 この設定は、オペレーショナル データが分析ストアに無期限に保持されることを示します

* 存在し、値が何らかの正の値 "n" に設定されている場合: 項目は、トランザクション ストアでの最後に変更時刻から "n" 秒後に、分析ストアでの期限が切れます。 この設定は、トランザクション ストアでのデータの保持に関係なく、分析ストアに一定期間だけオペレーショナル データを保持する場合に利用できます

考慮すべき点:

*   分析 TTL の値を設定して分析ストアを有効にした後で、別の有効な値に更新できます。 
*   トランザクション TTL はコンテナー レベルまたは項目レベルで設定できますが、現時点では、分析 TTL はコンテナー レベルでのみ設定できます。
*   コンテナー レベルで分析 TTL をトランザクション TTL 以上に設定することにより、分析ストアでのオペレーショナル データの長期保持を実現できます。
*   分析 TTL とトランザクション TTL を同じに設定することにより、分析ストアでトランザクション ストアをミラー化することができます。

コンテナーで分析ストアを有効にする方法:

* Azure portal から、分析 TTL オプションをオンにすると、既定値の -1 に設定されます。 この値は、データ エクスプローラーのコンテナーの設定に移動することで、"n" 秒に変更できます。 
 
* Azure Management SDK、Azure Cosmos DB SDK、PowerShell、または CLI から、これを -1 または "n" 秒に設定して、分析 TTL オプションを有効にできます。 

詳細については、[コンテナーで分析 TTL を構成する方法](configure-synapse-link.md#create-analytical-ttl)に関するページを参照してください。

## <a name="next-steps"></a>次のステップ

詳しく学習するために、次のドキュメントを参照してください。

* [Azure Synapse Link for Azure Cosmos DB](synapse-link.md)

* [Azure Synapse Analytics を使用してトランザクションと分析のハイブリッド処理を設計する](/learn/modules/design-hybrid-transactional-analytical-processing-using-azure-synapse-analytics/)方法に関する学習モジュールを確認する

* [Azure Synapse Link for Azure Cosmos DB の概要](configure-synapse-link.md)

* [Azure Cosmos DB の Synapse Link に関してよく寄せられる質問](synapse-link-frequently-asked-questions.yml)

* [Azure Synapse Link for Azure Cosmos DB のユース ケース](synapse-link-use-cases.md)
