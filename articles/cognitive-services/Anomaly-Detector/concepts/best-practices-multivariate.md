---
title: Anomaly Detector Multivariate API の使用に関するベスト プラクティス
titleSuffix: Azure Cognitive Services
description: Anomaly Detector Multivariate API を使用して時系列データに異常検出を適用するためのベスト プラクティス。
services: cognitive-services
author: mrbullwinkle
manager: nitinme
ms.service: cognitive-services
ms.subservice: anomaly-detector
ms.topic: conceptual
ms.date: 04/01/2021
ms.author: mbullwin
keywords: 異常検出, 機械学習, アルゴリズム
ms.openlocfilehash: 4114771276f4fec6dfef0e953ef9f52e165db510
ms.sourcegitcommit: 6ea4d4d1cfc913aef3927bef9e10b8443450e663
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 07/05/2021
ms.locfileid: "113297337"
---
# <a name="best-practices-for-using-the-anomaly-detector-multivariate-api"></a>Anomaly Detector 多変量 API の使用に関するベスト プラクティス

この記事では、多変量 Anomaly Detector (MVAD) API を使用する際の推奨プラクティスに関するガイダンスを提供します。 このチュートリアルでは、次のことについて説明します。

> [!div class="checklist"]
> * **API の使用方法**: エラーを発生させずに MVAD を使用する方法について説明します。
> * **データ エンジニアリング**: 高品質のデータを用意して MVAD がより高い精度で実行されるようにする方法について説明します。
> * **一般的な落とし穴**: 顧客が遭遇する一般的な落とし穴を回避する方法について説明します。
> * **FAQ**: よく寄せられる質問の回答について説明します。

## <a name="api-usage"></a>API の使用

MVAD の使用中にエラーが発生しないようにするには、このセクションの手順に従います。 それでもエラーが発生する場合は、[エラー コードの完全な一覧](./troubleshoot.md)を参照して、説明と対処法を確認してください。

[!INCLUDE [mvad-input-params](../includes/mvad-input-params.md)]

[!INCLUDE [mvad-data-schema](../includes/mvad-data-schema.md)]


## <a name="data-engineering"></a>Data Engineering

これで、MVAD API を使用して、コードをエラーなしで実行できます。 モデルの精度を向上させるために何ができるでしょうか?

### <a name="data-quality"></a>データ品質

* モデルは履歴データから標準パターンを学習するので、トレーニング データはシステムの **全体的な標準** 状態を表している必要があります。 モデルがこの種のパターンを学習するのは、トレーニング データに異常がいっぱい含まれている場合は困難です。 良好な精度を保つための経験上の異常率のしきい値は **1%** 以下です。
* 一般に、**トレーニング データの欠損値比率は 20% 未満である必要があります**。 欠損データが多すぎると、自動的に入力された値 (通常は線形値や定数値) が標準パターンであると学習される可能性があります。 これにより、実際の (欠損していない) データ ポイントが異常として検出される可能性があります。
    ただし、高い欠損率が許容される場合があります。 たとえば、`Outer` モードを使用してタイムスタンプを整理するグループに 2 つの変数 (時系列) があるとします。 1 つは 1 分間の細分性で、もう 1 つは 1 時間単位の細分性です。 時間単位の変数には、性質上 59/60 = 98.33% の欠損しているデータ ポイントがあります。 このような場合、時間単位の変数が通常は大きく変動しないのであれば、(欠損ではなく) 入手可能な値のみを使用して時間単位の変数に入力しても問題はありません。

### <a name="data-quantity"></a>データの数量

* MVAD の基になるモデルには、何百万ものパラメーターがあります。 最適なパラメーター セットを学習するには、最小数のデータ ポイントが必要です。 経験則によると、モデルを良好な精度でトレーニングするには、**変数ごとに 15,000 個以上のデータ ポイント (タイムスタンプ)** を用意する必要があります。 一般に、トレーニング データが多くなるにつれて、精度も向上します。 ただし、その量のデータを得ることができない場合でも、少ないデータで実験を行って、妥協した精度を許容できるかどうかを確認することをお勧めします。
* 毎回の推論 API の呼び出し時に、ソース データ ファイルに十分なデータ ポイントが含まれていることを確認する必要があります。 それは、通常は、`slidingWindow` に、推論結果が **本当に** 必要なデータ ポイントの数を加えたものになります。 たとえば、ストリーミングの場合、毎回 **1 つ** の新しいタイムスタンプで推論を行う場合、データ ファイルには先導 `slidingWindow` と **1 つ** のデータ ポイントのみを含めることができます。先に進んで、同じ数のデータ ポイント (`slidingWindow` + 1) を含む別の zip ファイルを作成できますが、"右" 側に 1 ステップ移動し、別の推論ジョブを実行します。 

    先導スライディング ウィンドウの先または "前" にあるものが推論結果に影響を与えることはなく、パフォーマンスのダウングレードのみを引き起こす可能性があります。それを下回るものは、`NotEnoughInput` エラーの原因になる可能性があります。


### <a name="timestamp-round-up"></a>タイムスタンプの切り上げ

変数のグループ (時系列) では、各変数を独立したソースから収集できます。 異なる変数のタイムスタンプは、互いに一貫性がなく、既知の頻度と一致しない可能性があります。 単純な例を次に示します。

*Variable-1*

| timestamp | value |
| --------- | ----- |
| 12:00:01  | 1.0   |
| 12:00:35  | 1.5   |
| 12:01:02  | 0.9   |
| 12:01:31  | 2.2   |
| 12:02:08  | 1.3   |

*Variable-2*

| timestamp | value |
| --------- | ----- |
| 12:00:03  | 2.2   |
| 12:00:37  | 2.6   |
| 12:01:09  | 1.4   |
| 12:01:34  | 1.7   |
| 12:02:04  | 2.0   |

30 秒ごとに 1 つのデータ ポイントを送信する 2 つのセンサーから、2 つの変数を収集しています。 ただし、センサーは正確な一定の頻度でデータ ポイントを送信しているのではなく、早くなる場合も遅くなる場合もあります。 MVAD では、さまざまな変数間の相関関係が考慮されるため、メトリックでシステムの状態を正しく反映できるように、タイムスタンプを適切に調整する必要があります。 上の例では、調整前に、変数 1 と変数 2 のタイムスタンプを頻度に合うように適切に "丸め" る必要があります。

事前処理が行われなかった場合、何が起こるかを見てみましょう。 `alignMode` を `Outer` (2 つのセットの和集合を意味します) に設定した場合、マージされたテーブルは次のようになります。

| timestamp | Variable-1 | Variable-2 |
| --------- | -------- | -------- |
| 12:00:01  | 1.0      | `nan`    |
| 12:00:03  | `nan`    | 2.2      |
| 12:00:35  | 1.5      | `nan`    |
| 12:00:37  | `nan`    | 2.6      |
| 12:01:02  | 0.9      | `nan`    |
| 12:01:09  | `nan`    | 1.4      |
| 12:01:31  | 2.2      | `nan`    |
| 12:01:34  | `nan`    | 1.7      |
| 12:02:04  | `nan`    | 2.0      |
| 12:02:08  | 1.3      | `nan`    |

`nan` は欠損値を示します。 明らかに、このマージされたテーブルは、期待していたものではありません。 変数 1 と変数 2 のインターリーブでは、MVAD モデルでそれらの相関関係に関する情報を抽出することはできません。 `alignMode` を `Inner` に設定した場合、変数 1 と変数 2 に共通するタイムスタンプが存在しないため、マージされたテーブルは空になります。

したがって、変数 1 と変数 2 のタイムスタンプを前処理する (最も近い 30 秒のタイムスタンプに丸める) 必要があり、新しい時系列は次のようになります。

*Variable-1*

| timestamp | value |
| --------- | ----- |
| 12:00:00  | 1.0   |
| 12:00:30  | 1.5   |
| 12:01:00  | 0.9   |
| 12:01:30  | 2.2   |
| 12:02:00  | 1.3   |

*Variable-2*

| timestamp | value |
| --------- | ----- |
| 12:00:00  | 2.2   |
| 12:00:30  | 2.6   |
| 12:01:00  | 1.4   |
| 12:01:30  | 1.7   |
| 12:02:00  | 2.0   |

これで、マージされたテーブルは、妥当なものになりました。

| timestamp | Variable-1 | Variable-2 |
| --------- | -------- | -------- |
| 12:00:00  | 1.0      | 2.2      |
| 12:00:30  | 1.5      | 2.6      |
| 12:01:00  | 0.9      | 1.4      |
| 12:01:30  | 2.2      | 1.7      |
| 12:02:00  | 1.3      | 2.0      |

近接しているタイムスタンプの異なる変数の値が適切に調整され、MVAD モデルで相関関係情報を抽出できるようになりました。

## <a name="common-pitfalls"></a>よくある落とし穴

[エラー コード テーブル](./troubleshoot.md)は別として、Microsoft では、MVAD API を使用しているときに陥りやすい落とし穴について、お客様から学んできています。 次の表は、これらの問題を回避するために役立ちます。

| 落とし穴 | 結果 |説明と解決方法 |
| --------- | ----- | ----- |
| トレーニング データや推論データのタイムスタンプが、各変数のそれぞれのデータ頻度に合うように丸められなかった。 | 推論結果のタイムスタンプが予想どおりではない。タイムスタンプが少なすぎるか多すぎる。  | 「[タイムスタンプの切り上げ](#timestamp-round-up)」をご覧ください。  |
| トレーニング データ内の異常なデータ ポイントが多すぎる。 | トレーニング中に異常なデータ ポイントが通常のパターンとして扱われるため、モデルの精度が悪影響を受ける。 | 経験上、異常率を **1%** 以下に保つことで改善されます。 |
| トレーニング データが少なすぎる。 | モデルの精度が落ちる。 | 経験上、MVAD モデルのトレーニングで良好な精度を維持するには、変数ごとに 15,000 個以上のデータポイント (タイムスタンプ) が必要です。|
| `isAnomaly`=`true` であるすべてのデータ ポイントを異常として取得する。 | 誤検出が多すぎる。 | `isAnomaly` と `severity` (または `score`) の両方を使用して、重大ではない異常を除外し、(必要に応じて) グループ化を使用して異常の持続時間を確認して、ランダム ノイズを抑制する必要があります。 `severity` と `score` の違いについては、下の「[FAQ](#faq)」セクションを参照してください。  |
| サブフォルダーが、トレーニングまたは推論用のデータ ファイル内に圧縮されている。 | トレーニングまたは推論時に、サブフォルダー内の csv データ ファイルが無視される。 | zip ファイルでは、サブフォルダーは許可されません。 詳細については、「[フォルダー構造](#folder-structure)」を参照してください。 |
| 推論データ ファイル内のデータが多すぎる。例: すべての履歴データを推論データ zip ファイルに圧縮している | エラーは表示されない可能性はあるが、Azure Blob に zip ファイルをアップロードしようとしたときや、推論を実行しようとしたときに、パフォーマンスが低下する。 | 詳細については、「[データの数量](#data-quantity)」を参照してください。 |
| MVAD がまだサポートされていない Azure リージョンでの Anomaly Detector リソースの作成と MVAD API の呼び出し。  | MVAD API の呼び出し中に "リソースが見つかりません" というエラーが発生する。 | プレビュー段階では、MVAD は限られたリージョンでのみ利用できます。 「[Anomaly Detector の新機能](../whats-new.md)」をブックマークして、常に MVAD リージョンのロールアウトに関する最新情報を確認してください。 また、GitHub の問題を報告したり、AnomalyDetector@microsoft.com に連絡して特定のリージョンをリクエストすることもできます。 |

## <a name="faq"></a>よく寄せられる質問

### <a name="how-does-mvad-sliding-window-work"></a>MVAD のスライディング ウィンドウのしくみ

2 つの例を使用して、MVAD のスライディング ウィンドウのしくみを学びましょう。 `slidingWindow` = 1,440 と設定し、入力データの細分性が 1 分であるとします。

* **ストリーミング シナリオ**: 1 つのデータ ポイント "2021-01-02T00:00:00Z" が異常であるかどうかを予測します。 `startTime` と `endTime` は同じ値 ("2021-01-02T00:00:00Z") になります。 ただし、推論データ ソースには、少なくとも 1,440 + 1 個のタイムスタンプが含まれている必要があります。 理由は、MVAD では、ターゲット データ ポイント ("2021-01-02T00:00: 00Z") の前にある先導データを取得して、ターゲットが異常であるかどうかが判断されるためです。 この例では、必要な先導データの長さは `slidingWindow` (1,440) です。 1,440 = 60 * 24 であるため、入力データは、遅くても "2021-01-01T00:00:00Z" から始まる必要があります。

* **バッチ シナリオ**: 予測するターゲット データ ポイントが複数あります。 `endTime` は、`startTime` よりも大きくなります。 このようなシナリオでの推論は、"移動ウィンドウ" という方法で実行されます。 たとえば、MVAD では、`2021-01-01T00:00:00Z` から `2021-01-01T23:59:00Z` (この値を含む) までのデータを使用して、`2021-01-02T00:00:00Z` のデータが異常かどうかを判断します。 次に、前方に移動して、`2021-01-01T00:01:00Z` から `2021-01-02T00:00:00Z` (この値を含む) までのデータを使用して、`2021-01-02T00:01:00Z` のデータが異常かどうかを判断します。 `endTime` に指定された最後のタイムスタンプ (または実際の最後のタイムスタンプ) まで、同じ方法で (比較する 1,440 個のデータ ポイントを取得しながら) 移動していきます。 そのため、推論データ ソースには、`startTime` - `slidingWindow` から始まるデータが含まれている必要があり、合計サイズが `slidingWindow` + (`endTime` - `startTime`) であることが理想です。

### <a name="why-only-accepting-zip-files-for-training-and-inference"></a>トレーニングと推論で zip ファイルのみが容認される理由

zip ファイルを使用するのは、バッチ シナリオでは、トレーニング データと推論データの両方のサイズが非常に大きくなることが予想され、HTTP 要求の本文に含めることができないためです。 これにより、ユーザーは、モデルの検証またはデータ分析のために、履歴データに対するバッチ推論を実行できます。

ただし、これは、ストリーミングの推論と高頻度データでは不便な場合があります。 ユーザーが要求本文にデータを渡すことができる、ストリーミングの推論用に特別に設計された新しい API の追加が予定されています。

### <a name="whats-the-difference-between-severity-and-score"></a>`severity` と `score` の違い

通常は、ビジネスにとってあまり重要ではない "異常" を除外するフィルターとして `severity` を使用することをお勧めします。 シナリオとデータ パターンによって異なりますが、重要度が低いこれらの異常では、`severity` 値が比較的低いか、ランダムなスパイクのような独立した (不連続の) 高い `severity` 値であることがほとんどです。

`severity` のしきい値や高い `severity` 値の継続時間よりも高度なルールが必要な場合は、`score` を使用してさらに強力なフィルターを設定できます。 MVAD による `score` を使用した異常の判断方法を理解しておくと、役に立つ可能性があります。

データ ポイントの異常は、グローバルとローカルの両方の観点から検討されます。 タイムスタンプの `score` が特定のしきい値を上回っている場合、そのタイムスタンプは異常とマークされます。 `score` はしきい値未満であるが、セグメント内で相対的に高い場合も、異常とマークされます。

## <a name="next-steps"></a>次のステップ

* [クイックスタート: Anomaly Detector 多変量クライアント ライブラリを使用する](../quickstarts/client-libraries-multivariate.md)。
* [Anomaly Detector Multivariate を動かす、基になるアルゴリズムについて説明します](https://arxiv.org/abs/2009.02040)
