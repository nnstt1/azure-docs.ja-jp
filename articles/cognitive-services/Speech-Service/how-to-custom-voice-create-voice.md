---
title: Custom Voice を作成する - Speech サービス
titleSuffix: Azure Cognitive Services
description: 実際のデータをアップロードする準備ができたら、Custom Voice ポータルに移動します。 Custom Voice プロジェクトを作成するか、選択します。 このプロジェクトでは、実際の音声トレーニングに使用するデータとして適切な言語またはロケールと性別プロパティを共有する必要があります。
services: cognitive-services
author: eric-urban
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 11/04/2019
ms.author: eur
ms.openlocfilehash: 16f9d66b669e792d0bccc2676bdc1db327de3229
ms.sourcegitcommit: 2cc9695ae394adae60161bc0e6e0e166440a0730
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/03/2021
ms.locfileid: "131507210"
---
# <a name="create-and-use-your-voice-model"></a>音声モデルを作成して使用する

「[カスタム音声を作成するためのデータを準備する](how-to-custom-voice-prepare-data.md)」では、カスタム ニューラル音声および別の形式の要件をトレーニングするために使用できるさまざまなデータ型について学習しました。 データとボイス タレントの口述の準備ができたら、[Speech Studio](https://aka.ms/custom-voice-portal) へのアップロードを開始できます。 この記事では、Speech Studio ポータルを使用してカスタム ニューラル音声をトレーニングする方法について説明します。 カスタム ニューラル音声で[サポートされる言語](language-support.md#customization)を参照してください。

## <a name="prerequisites"></a>前提条件

* [カスタム ニューラル音声の概要](how-to-custom-voice.md)に関するページを完了する
* [カスタム音声を作成するためのデータを準備する](how-to-custom-voice-prepare-data.md)

## <a name="set-up-voice-talent"></a>ボイス タレントを設定する

ボイス タレントは個人または対象話者であり、その音声が録音され、ニューラル音声モデルの作成に使用されます。 音声を作成する前に、音声のペルソナを定義して、適切なボイス タレントを選択します。 音声サンプルの録音の詳細については、[チュートリアル](record-custom-voice-samples.md)を参照してください。

ニューラル音声をトレーニングするには、ボイス タレントのプロファイルと共に、自分の音声データがカスタム音声モデルのトレーニングに使用されることに関する同意をボイス タレントが録音したオーディオ ファイルを作成する必要があります。 録音スクリプトを準備するときは、以下の文を必ず含めてください。

**"I [state your first and last name] am aware that recordings of my voice will be used by [state the name of the company] to create and use a synthetic version of my voice." (私 [自分の姓名] は、私の音声の合成バージョンを作成して使用するために、私の音声が [会社名] によって使用されることを承知しています。)**
この文は、トレーニング データが同意の口述の音声と一致するかどうかを確認するために使用されます。 詳細については、[ボイス タレントの検証](/legal/cognitive-services/speech-service/custom-neural-voice/data-privacy-security-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)に関する記事を参照してください。

> [!NOTE]
> カスタム ニューラル音声を利用するためのアクセスには制限があります。 [責任ある AI の要件](/legal/cognitive-services/speech-service/custom-neural-voice/limited-access-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)について理解してから、[アクセスを申請](https://aka.ms/customneural)してください。 

次の手順では、ボイス タレントによる音声同意ファイルが準備されていることを前提としています。  [Speech Studio](https://aka.ms/custom-voice-portal) に移動してカスタム ニューラル音声プロジェクトを選択し、次の手順に従って、ボイス タレントのプロファイルを作成します。

1. **[音声合成]**  >  **[Custom Voice]**  >  **[プロジェクトの選択]**  >  **[ボイス タレントの設定]** に移動します。

2. **[ボイス タレントの追加]** を選択します。

3. 次に、音声の特性を定義するために、使用する **[ターゲット シナリオ]** を選択します。 **[音声の特性]** を記述します。

> [!NOTE]
> 指定するシナリオは、申請フォームで申請したものと一致している必要があります。

4. 次に、 **[ボイス タレントの口述のアップロード]** に移動し、指示に従って、事前に準備したボイス タレントの口述をアップロードします。

> [!NOTE]
> 口述は、録音環境や話し方のスタイルを含め、トレーニング データと同じ設定で録音するようにしてください。

5. 最後に、 **[確認と作成]** に移動して設定を確認し、 **[送信]** を選択します。

## <a name="upload-your-data"></a>データをアップロードする

データをアップロードする準備ができたら、 **[トレーニング データの準備]** タブに移動し、最初のトレーニング セットを追加してデータをアップロードします。  トレーニング セットは、音声モデルのトレーニングに使用される一連の音声発話とそのマッピング スクリプトです。 トレーニング セットを使用すると、トレーニング データを整理することができます。 データの準備状況のチェックは、トレーニング セットごとに実行されます。 複数のデータをトレーニング セットにインポートできます。

トレーニング データを作成して確認するには、次の手順を実行します。

1. **[トレーニング データの準備]** タブで、 **[トレーニングセットの追加]** を選択して **[名前]** と **[説明]** を入力し、 **[作成]** を選択して新しいトレーニング セットを追加します。

   トレーニング セットが正常に作成されたら、データのアップロードを開始できます。 

2. データをアップロードするには、 **[データのアップロード]**  >  **[データ型の選択]**  >  **[データのアップロード]** > **[ターゲット トレーニング セットの指定]** を選択し、データの **[名前]** と **[説明]** を入力し、設定を確認して **[送信]** を選択します。

> [!NOTE]
>- 重複したオーディオ名はトレーニングから削除されます。 選択したデータ内の 1 つの .zip ファイルまたは複数の .zip ファイルに同じオーディオ名が含まれていないことを確認してください。 (オーディオ ファイルまたはスクリプト ファイル内の) 発話 ID が重複している場合、それらは拒否されます。
>- 以前のバージョンの Speech Studio でデータ ファイルを作成している場合、それらを使用するには、事前にデータのトレーニング セットを指定する必要があります。 そうしないと、データ名に感嘆符が追加され、そのデータを使用できなくなります。

アップロードする各データでは、選択したデータの種類の要件が満たされている必要があります。 データをアップロードする前に適切に書式設定することが重要です。これにより、カスタム ニューラル音声サービスによってデータが正確に処理されるようになります。 「[カスタム音声を作成するためのデータを準備する](how-to-custom-voice-prepare-data.md)」に移動し、データが正しく書式設定されていることを確認します。

> [!NOTE]
> - Standard サブスクリプション (S0) ユーザーは、5 個のデータ ファイルを同時にアップロードできます。 制限に達した場合は、少なくとも 1 つのデータ ファイルのインポートが終わるまで待機します。 その後、やり直してください。
> - サブスクリプションごとにインポートできるデータ ファイルの最大数は、Free サブスクリプション (F0) ユーザーの場合は .zip ファイル 10 個、Standard サブスクリプション (S0) ユーザーの場合は 500 個です。

**[送信]** ボタンを押すと、データ ファイルが自動的に検証されます。 データ検証には、ファイル形式、サイズ、サンプリング レートを確認する、オーディオ ファイルの一連のチェックが含まれます。 エラーが見つかった場合は、修正して、もう一度送信します。 

データがアップロードされたら、トレーニング セットの詳細ビューで詳細を確認できます。 **[概要]** タブでは、各データの発音スコアとノイズ レベルをさらにチェックできます。 発音スコアの範囲は 0 ～ 100 です。 スコアが 70 未満の場合は、通常、音声のエラーまたはスクリプトの不一致を示しています。 アクセントが強いと発音スコアが下がることがあり、生成されるデジタル音声に影響します。

高い信号雑音比 (SNR) は、オーディオのノイズが低いことを示します。 一般に、専門スタジオでの録音によって、SNR が 50 以上に達するようにできます。 SNR が 20 未満のオーディオでは、生成される音声に明らかなノイズが含まれる可能性があります。

発音スコアが低い場合や SNR が悪い場合は、発話を録音し直すことを検討してください。 再録音できない場合は、それらの発話をデータから除外することを検討してください。

**[データの詳細]** では、トレーニング セットのデータの詳細を確認できます。 データに関する一般的な問題が発生した場合は、表示されたメッセージの指示に従って、トレーニング前に修正してください。

これらの問題は 3 つの種類に分類されます。 次の 3 つの表を参照して、それぞれのエラーの種類を確認します。

以下の表に示す最初の種類のエラーは、手動で修正してください。そうしないと、これらのエラーを含むデータがトレーニング中に除外されます。

| カテゴリ | 名前 | 説明 |
| --------- | ----------- | --------------------------- |
| スクリプト | 無効な区切り記号| 発話 ID とスクリプト コンテンツは TAB 文字で分離する必要があります。|
| スクリプト | 無効なスクリプト ID| スクリプト行 ID は数値である必要があります。|
| Script | 重複したスクリプト|スクリプト コンテンツの各行は一意である必要があります。 この行は {} と重複しています。|
| Script | スクリプトが長すぎる| スクリプトは、1,000 文字未満にする必要があります。|
| Script | 一致するオーディオがない| 各発話 (スクリプト ファイルの各行) の ID は、オーディオ ID と一致する必要があります。|
| スクリプト | 有効なスクリプトがない| このデータセットで有効なスクリプトが見つかりませんでした。 詳細な問題リストに表示されるスクリプト行を修正します。|
| オーディオ | 一致するスクリプトがない| このスクリプト ID と一致するオーディオ ファイルはありません。 wav ファイルの名前は、スクリプト ファイル内の ID と一致する必要があります。|
| オーディオ | 無効なオーディオ形式| .wav ファイルのオーディオ形式が無効です。 [SoX](http://sox.sourceforge.net/) のようなオーディオ ツールを使用して wav ファイルの形式を確認してください。|
| オーディオ | サンプリング レートが低い| .wav ファイルのサンプリング レートを 16 KHz 未満にすることはできません。|
| オーディオ | 音声が長すぎる| 音声の長さが 30 秒を超えています。 長い音声を複数のファイルに分割してください。 発話は 15 秒未満の長さにすることをお勧めします。|
| オーディオ | 有効な音声がない| このデータセットには有効な音声が見つかりません。 音声データを確認して、もう一度アップロードしてください。|

以下の表に示されている 2 番目の種類のエラーは自動的に修正されますが、修正されたデータをダブルチェックすることをお勧めします。

| カテゴリ | 名前 | 説明 |
| --------- | ----------- | --------------------------- |
| オーディオ | ステレオ音声の自動修正 | オーディオのサンプル録音ではモノラルを使用します。 ステレオ音声チャンネルは自動的にモノラル チャンネルにマージされるため、コンテンツが失われる可能性があります。  正規化されたデータセットをダウンロードして確認してください。|
| ボリューム | ボリューム ピークの自動修正 |ボリューム ピークは、-3 dB (最大ボリュームの 70%) から -6 dB (50%) の範囲内である必要があります。 サンプル録音中またはデータの準備中にボリューム ピークを制御します。 この音声は、自動的にピーク範囲に合わせて線形的にスケーリングされます (-4 dB または 65%)。 正規化されたデータセットをダウンロードして確認してください。|
|不一致 | 無音の自動修正| 冒頭の無音が 200 ミリ秒を超えていることが検出され、自動的に 200 ミリ秒にトリミングされました。 正規化されたデータセットをダウンロードして確認してください。 |
| 不一致 |無音の自動修正 | 末尾の無音が 200 ミリ秒を超えていることが検出され、自動的に 200 ミリ秒にトリミングされました。 正規化されたデータセットをダウンロードして確認してください。 |
| 不一致 |無音の自動修正 |冒頭の無音が 100 ミリ秒より短いことが検出され、自動的に 100 ミリ秒に延長されました。 正規化されたデータセットをダウンロードして確認してください。 |
| 不一致 |無音の自動修正 | 末尾の無音が 100 ミリ秒より短いことが検出され、自動的に 100 ミリ秒に延長されました。 正規化されたデータセットをダウンロードして確認してください。|

以下の表に示されている 3 番目の種類のエラーは修正されませんが、これらのエラーを含むデータはトレーニング中に除外されず、トレーニングの品質に影響します。 より高品質のトレーニングを行う場合は、これらのエラーを手動で修正することをお勧めします。 

| カテゴリ | 名前 | 説明 |
| --------- | ----------- | --------------------------- |
| Script | 正規化されていないテキスト|このスクリプトには、0 から 9 の数字が含まれています。 これらを正規化された単語に展開して、音声と一致させます。 たとえば、"123" を "one hundred and twenty-three" に正規化します。|
| Script | 正規化されていないテキスト|このスクリプトには、記号 {} が含まれています。 音声に一致するように記号を正規化します。 たとえば、"50%" を "fifty percent" にします。|
| Script | 質問の発話が十分ではない| 全体の発話のうち、少なくとも 10% は質問文である必要があります。 これにより、音声モデルが質問のトーンを適切に表現できるようになります。|
| Script |感嘆の発話が十分ではない| 全体の発話のうち、少なくとも 10% は感嘆文である必要があります。 これにより、音声モデルが感嘆のトーンを適切に表現できるようになります。|
| オーディオ| ニューラル音声のサンプリング レートが低い | ニューラル音声を作成する際には、.wav ファイルのサンプリング レートを 24 KHz 以上に設定することをお勧めします。 低い場合は、24 KHz に自動的にアップサンプリングされます。|
| ボリューム |全体的にボリュームが低すぎる|ボリュームは -18 dB (最大ボリュームの 10%) より低くすることはできません。 サンプル録音中またはデータの準備時に、ボリュームの平均レベルが適切な範囲内になるように制御してください。|
| ボリューム | ボリュームのオーバーフロー| オーバーフローしているボリュームが {} で検出されています。 ピーク値でのボリュームのオーバーフローを回避するように録音装置を調整してください。|
| ボリューム | 冒頭の無音の問題 | 最初の 100 ミリ秒の無音がクリーンではありません。 録音のノイズ フロア レベルを下げ、最初の 100 ミリ秒を冒頭無音のままにします。|
| ボリューム| 末尾の無音の問題| 最後の 100 ミリ秒の無音がクリーンではありません。  録音のノイズ フロア レベルを下げ、最後の 100 ミリ秒を末尾無音のままにします。|
| 不一致 | スコアが低い単語|スクリプトと音声コンテンツを調べて、それらが一致していることを確認し、ノイズ フロア レベルを制御します。 長い無音の長さを短縮するか、長すぎる場合は音声を複数の発話に分割します。|
| 不一致 | 冒頭の無音の問題 |最初の単語の前に余分な音声が聞こえました。 スクリプトと音声コンテンツを調べて、それらが一致していることを確認し、ノイズ フロア レベルを制御し、最初の 100 ミリ秒が無音になるようにします。|
| 不一致 | 末尾の無音の問題| 最後の単語の後に余分な音声が聞こえました。 スクリプトと音声コンテンツを調べて、それらが一致していることを確認し、ノイズ フロア レベルを制御し、最後の 100 ミリ秒が無音になるようにします。|
| 不一致 | 信号対雑音比が低い | 音声の SNR レベルが 20 dB より低くなっています。 少なくとも 35 dB をお勧めします。|
| 不一致 | 使用可能なスコアがない |この音声の音声コンテンツを認識できませんでした。 音声とスクリプト コンテンツを調べて、音声が有効であり、スクリプトと一致していることを確認します。|

## <a name="train-your-custom-neural-voice-model"></a>カスタム ニューラル音声モデルをトレーニングする

データ ファイルが検証されたら、それを使用してカスタム ニューラル音声モデルを作成できます。

1. **[モデルのトレーニング]** タブで **[モデルのトレーニング]** を選択し、アップロードしたデータを使用して音声モデルを作成します。

2. モデルとターゲット言語のニューラル トレーニング方法を選択します。

既定では、音声モデルはトレーニング データと同じ言語でトレーニングされます。 音声モデルのセカンダリ言語を作成する (プレビュー) ために選択することもできます。  カスタム ニューラル音声でサポートされる言語と言語間機能を確認します ([カスタマイズ用の言語](language-support.md#customization))。

カスタム ニューラル音声のトレーニングは無料ではありません。 詳細については[価格](https://azure.microsoft.com/pricing/details/cognitive-services/speech-services/)のページを確認してください。 ただし、S0 の Speech リソースを使用して 2021 年 3 月 31 日より前にデプロイされた統計的パラメトリックまたは連結音声モデルがある場合は、無料のニューラル トレーニング クレジットが Azure サブスクリプションに提供されており、5 つの異なるバージョンのニューラル音声を無料でトレーニングできます。

3. 次に、トレーニングに使用するデータを選択し、話者ファイルを指定します。

>[!NOTE]
>- カスタム ニューラル音声を作成するには、少なくとも 300 個の発話を選択する必要があります。
>- ニューラル音声をトレーニングするには、ボイス タレントのプロファイルと共に、自分の音声データがカスタム音声モデルのトレーニングに使用されることをボイス タレントが承認している音声同意ファイルを指定する必要があります。 カスタム ニューラル音声を利用するためのアクセスには制限があります。 [責任ある AI の要件](/legal/cognitive-services/speech-service/custom-neural-voice/limited-access-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)について理解し、[こちらのアクセスを適用](https://aka.ms/customneural)してください。

4. 次にテスト スクリプトを選択します。

トレーニングごとに、既定のスクリプトによるモデルのテストに役立つ 100 個のサンプル オーディオ ファイルが自動的に生成されます。 独自のテスト スクリプトを省略可能として提供することもできます。 テスト スクリプトでは、ファイル名 (各発話の ID) を除外する必要があります。それ以外の場合は、これらの ID が読み上げられます。 1 つの .txt ファイル内での発話の構成に関する例を次に示します。

```
This is the waistline, and it's falling.
We have trouble scoring.
It was Janet Maslin.
```

発話の段落ごとに、個別の音声になります。 すべての文を 1 つの音声に結合したい場合は、1 つの段落にします。

>[!NOTE]
>- テスト スクリプトは、1 MB 未満の txt ファイルである必要があります。 サポートされているエンコード形式は、ANSI/ASCII、UTF-8、UTF-8-BOM、UTF-16-LE、または UTF-16-BE です。  
>- 生成されたオーディオは、アップロードされたテスト スクリプトと既定のテスト スクリプトを組み合わせたものです。

5. このモデルを識別しやすい **[名前]** と **[説明]** を入力します。

名前は慎重に選択します。 ここで入力する名前が、SSML 入力の一部としての音声合成の要求時に、音声を指定するために使用する名前になります。 アルファベット、数字、およびいくつかの区切り文字 (-、_、および ("、") など) だけを使用できます。 ニューラル音声モデルごとに、異なる名前を使用します。

**[説明]** フィールドの一般的な用途は、モデルの作成に使用されたデータの名前を記録することです。

6. 設定を確認してから、 **[送信]** を選択してモデルのトレーニングを開始します。

> [!NOTE]
> 重複したオーディオ名はトレーニングから削除されます。 選択したデータ内の複数の .zip ファイルに同じオーディオ名が含まれていないことを確認してください。

**[モデルのトレーニング]** の表に、この新しく作成されたモデルに対応する新しいエントリが表示されます。 この表には、次の状態も表示されます。処理中、成功、失敗。

表示される状態には、ここに示すように、データから音声モデルへの変換プロセスが反映されます。

| State | 意味 |
| ----- | ------- |
| 処理中 | 実際の音声モデルを作成中です。 |
| 成功 | 実際の音声モデルは作成が済み、デプロイ可能です。 |
| 失敗 | 未知のデータの問題やネットワークの問題など、さまざまな理由のために、トレーニング中に音声モデルが失敗しました。 |

トレーニング期間は、トレーニングするデータ量によって異なります。 カスタム ニューラル音声をトレーニングするには、平均で約 40 コンピューティング時間かかります。 

> [!NOTE]
> Standard サブスクリプション (S0) ユーザーは、3 つの音声を同時にトレーニングできます。 制限に達した場合は、少なくとも 1 つの音声モデルのトレーニングが終わるまで待ってから、やり直します。 

7. モデルのトレーニングが正常に完了したら、モデルの詳細を確認できます。

音声モデルが正常に作成されたら、デプロイして使用する前に、生成されたサンプル オーディオ ファイルを使用してテストすることができます。

音声の品質は、トレーニング データのサイズ、録音の品質、トランスクリプト ファイルの正確さ、トレーニング データに録音された音声が目的のユース ケースに合わせて設計された音声の性格とどの程度一致しているかなど、さまざまな要因に依存します。 [テクノロジの機能と制限、およびモデルの品質を向上させるためのベスト プラクティスの詳細については、こちらを確認してください](/legal/cognitive-services/speech-service/custom-neural-voice/characteristics-and-limitations-custom-neural-voice?context=%2fazure%2fcognitive-services%2fspeech-service%2fcontext%2fcontext)。 

## <a name="create-and-use-a-custom-neural-voice-endpoint"></a>カスタム ニューラル音声のエンドポイントを作成して使用する

音声モデルの作成とテストが正常に終了したら、カスタム Text-to-Speech エンドポイントに展開します。 その後は、REST API で Text-to-Speech 要求を行うときの通常のエンドポイントの代わりに、このエンドポイントを使います。 カスタム エンドポイントは、モデルをデプロイするときに使用したサブスクリプションからのみ呼び出すことができます。

カスタム ニューラル音声のエンドポイントを作成するには、次の手順を実行します。

1. **[モデルのデプロイ]** タブで、 **[モデルのデプロイ]** を選択します。 
2. 次に、カスタム エンドポイントの **[名前]** と **[説明]** を入力します。
3. 次に、このエンドポイントに関連付ける音声モデルを選択します。 
4. 最後に、 **[デプロイ]** を選択してエンドポイントを作成します。

**[デプロイ]** をクリックすると、エンドポイントの表に新しいエンドポイントのエントリが表示されます。 新しいエンドポイントのインスタンス化には、数分かかることがあります。 展開の状態が **[Succeeded]\(成功\)** の場合、エンドポイントを使用する準備ができています。

常に使用するのでない場合は、エンドポイントを **中断** して **再開** することができます。 中断後にエンドポイントが再アクティブ化されるとき、エンドポイントの URL は同じままになるので、アプリのコードを変更する必要はありません。 

また、エンドポイントを新しいモデルに更新することもできます。 モデルを変更するには、必ず新しいモデルの名前を更新するモデルと同じにします。 

> [!NOTE]
>- Standard サブスクリプション (S0) ユーザーは、独自のカスタム ニューラル音声がそれぞれ使用される最大 50 個のエンドポイントを作成できます。
>- カスタム ニューラル音声を使用するには、音声モデルの名前を指定して、HTTP 要求に直接カスタム URI を使用し、同じサブスクリプションを使用して TTS サービスの認証を通過する必要があります。

ご自分のエンドポイントがデプロイされると、エンドポイント名はリンクとして表示されます。 リンクをクリックすると、エンドポイント キー、エンドポイントの URL、サンプル コードなど、ご自分のエンドポイントに固有の情報が表示されます。

カスタム エンドポイントの機能は、テキスト読み上げ要求に使用される標準のエンドポイントと同じです。  詳細については、[Speech SDK](./get-started-text-to-speech.md) または [REST API](rest-text-to-speech.md) に関する記事を参照してください。

また、使いやすい UI を使用して音声出力を微調整できるオンライン ツール [Audio Content Creation](https://speech.microsoft.com/audiocontentcreation) も提供しています。

## <a name="next-steps"></a>次のステップ

- [音声サンプルを録音する方法](record-custom-voice-samples.md)
- [Text-to-Speech API リファレンス](rest-text-to-speech.md)
- [Long Audio API](long-audio-api.md)
