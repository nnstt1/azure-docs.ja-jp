---
title: キーワード認識 - Speech サービス
titleSuffix: Azure Cognitive Services
description: Speech Software Development Kit (SDK) を使用したキーワード認識の特徴、機能、制限の概要。
services: cognitive-services
author: hasyashah
manager: nitinme
ms.service: cognitive-services
ms.subservice: speech-service
ms.topic: conceptual
ms.date: 04/30/2021
ms.author: hasshah
ms.custom: devx-track-csharp, ignite-fall-2021
ms.openlocfilehash: a91f3e6e59647d6817f05137e284fbee4400dbd8
ms.sourcegitcommit: 362359c2a00a6827353395416aae9db492005613
ms.translationtype: HT
ms.contentlocale: ja-JP
ms.lasthandoff: 11/15/2021
ms.locfileid: "132491812"
---
# <a name="keyword-recognition"></a>キーワード認識

キーワード認識では、オーディオのストリーム内の単語や短いフレーズが検出されます。 キーワード スポッティングとも呼ばれます。 

キーワード認識の最も一般的なユース ケースは、仮想アシスタントの音声による有効化です。 たとえば、"コルタナさん" は、Cortana アシスタントのキーワードです。 キーワードを認識すると、シナリオ固有のアクションが実行されます。仮想アシスタントのシナリオでは、一般的なアクションとして、キーワードの後に続くオーディオの音声認識が挙げられます。

通常、仮想アシスタントは常にリッスンしています。 キーワード認識は、ユーザーのプライバシー境界として機能します。 キーワード要件はゲートとして機能します。これにより、関連のないユーザー オーディオがローカル デバイスを通過してクラウドに到達しないようにします。

精度、待機時間、計算の複雑さのバランスを取るために、キーワード認識はマルチステージ システムとして実装されます。 最初のステージを超えると、後続のステージでは、その前のステージで対象のキーワードが認識された場合にのみオーディオが処理されます。

現在のシステムは、次のように、エッジとクラウドにまたがる複数のステージで設計されています。

![エッジとクラウドにまたがるキーワード認識の複数ステージ。](media/custom-keyword/kw-recognition-multi-stage.png)

キーワード認識の精度は、次のメトリックによって測定されます。
* **本人受入率 (CA)** - エンドユーザーが読み上げたときに、キーワードを認識するシステムの能力を測定します。 これは、真陽性率とも呼ばれます。 
* **他人受入率 (FA)** - エンドユーザーが読み上げていないキーワードの音声を除外するシステムの能力を測定します。 これは、擬陽性率とも呼ばれます。

目標は、他人受入率を最小限に抑えながら、本人受入率を最大化することです。 現在のシステムは、短期間の無音に続くキーワードまたは語句を検出するように設計されています。 文または発話の途中でキーワードを検出することはできません。

## <a name="custom-keyword-for-on-device-models"></a>オンデバイス モデルの Custom Keyword

[Speech Studio の Custom Keyword ポータル](https://speech.microsoft.com/customkeyword)を使用すると、単語または短い語句を指定することによって、エッジで実行されるキーワード認識モデルを生成できます。 適切な発音を選択してキーワード モデルをさらにパーソナライズすることができます。

### <a name="pricing"></a>価格

Basic モデルでも、Advanced モデルでも、モデルを生成するための Custom Keyword の使用にはコストはかかりません。 また、Speech SDK を使用してオンデバイス モデルを実行する場合もコストはかかりません。

### <a name="types-of-models"></a>モデルの種類

Custom Keyword を使用すると、任意のキーワードに対して 2 種類のオンデバイス モデルを生成できます。

| モデルの種類 | 説明 |
| ---------- | ----------- |
| Basic | デモまたは迅速なプロトタイプ作成に最適です。 モデルは一般的なベース モデルで生成され、準備が整うのに最大 15 分かかる場合があります。 モデルに、最適な精度特性が備わっていない場合があります。 |
| 上級 | 成果物統合に最適です。 モデルは、シミュレートされたトレーニング データを使用して一般的なベース モデルを適応しながら生成され、精度特性が向上します。 モデルが使用できるようになるまで、最大で 48 時間かかる可能性があります。 |

> [!NOTE]
> **Advanced** モデルの種類をサポートするリージョンの一覧は、[キーワード認識リージョンのサポート](keyword-recognition-region-support.md) ドキュメントで確認できます。 

どちらの種類のモデルでも、トレーニング データをアップロードする必要はありません。 Custom Keyword によって、データ生成とモデル トレーニングが完全に処理されます。

### <a name="pronunciations"></a>発音

新しいモデルが作成されると、Custom Keyword によって提供されたキーワードの発音候補が自動的に生成されます。 それぞれの発音を聞き、エンドユーザーがキーワードを発話する方法に近いと思われるすべての発音を選択します。 その以外の発音は選択しません。

最適な精度特性を獲得するために、選択する発音について慎重に考慮することが重要です。 たとえば、必要以上の発音を選択すると、他人受入率が高くなる可能性があります。 期待されるバリエーションがカバーされないほど発音が少ないと、本人受入率が低くなる可能性があります。

### <a name="testing-models"></a>モデルのテスト

オンデバイス モデルが Custom Keyword によって生成されると、それらはポータルで直接テストできます。 ポータルを使用すると、ブラウザーに直接発話し、キーワード認識の結果を取得することができます。

## <a name="keyword-verification"></a>キーワード検証

キーワード検証は、Azure で実行されている堅牢なモデルを使用して、オンデバイス モデルで誤って受け入れてしまうことの影響を軽減するクラウド サービスです。 キーワード検証で独自のキーワードを使用する際に、チューニングやトレーニングは必要ありません。 精度と待機時間を向上させるために、増分モデルの更新がサービスに継続的にデプロイされ、クライアント アプリケーションに対して完全に透過的に行われます。

### <a name="pricing"></a>価格

キーワード検証は、常に音声テキスト変換と組み合わせて使用されます。また、音声テキスト変換にかかるコストを超えて、キーワード検証の使用に対してコストがかかることはありません。

### <a name="keyword-verification-and-speech-to-text"></a>キーワード検証と音声テキスト変換

キーワード検証を使用する場合は、常に音声テキスト変換と組み合わせて使用されます。 両方のサービスは並行して実行されます。 つまり、同時に処理するために、両方のサービスにオーディオが送信されることを意味します。

![キーワード検証と音声テキスト変換の並列処理。](media/custom-keyword/kw-verification-parallel-processing.png)

キーワード検証と音声テキスト変換を並行して実行することには、次のような利点があります。
* **音声テキスト変換の結果を得るための追加の待機時間がない** - 並行して実行することにより、キーワード検証に待機時間が追加されません。また、クライアントは音声テキスト変換の結果をすぐに受け取ることができます。 キーワード検証によって、キーワードがオーディオ内に存在しないと判断された場合は、音声テキスト変換の処理が終了します。そうすることで、音声テキスト変換で不要な処理が実行されません。 ただし、ネットワークおよびクラウド モデルの処理では、ユーザーに認識される音声による有効化の待機時間が長くなります。 詳細については、[推奨事項とガイドライン](keyword-recognition-guidelines.md)に関するページを参照してください。
* **音声テキスト変換の結果で強制されるキーワード プレフィックス** - 音声テキスト変換の処理では、クライアントに送信される結果の先頭にキーワードが付きます。 これにより、キーワードに続く音声に対する音声テキスト変換の結果の精度が向上します。
* **音声テキスト変換のタイムアウトの延長** - オーディオの開始部にキーワードが想定されているため、音声テキスト変換では、音声の終わりを確認し、音声テキスト変換の処理を終了する前に、キーワードの後に最大 5 秒の待機時間を設定できます。 これにより、ステージングされたコマンド ( *\<keyword> \<pause> \<command>* ) とチェーンされたコマンド ( *\<keyword> \<command>* ) の両方でエンドユーザー エクスペリエンスが正しく処理されるようになります。 

### <a name="keyword-verification-responses-and-latency-considerations"></a>キーワード検証の応答と待機時間に関する考慮事項

キーワード検証では、サービスへの要求ごとに、2 つの応答 (受入または拒否) のいずれかが返されます。 処理の待機時間は、キーワードの長さと、キーワードを含むと期待されるオーディオ セグメントの長さによって異なります。 処理の待機時間には、クライアントと Azure Speech サービスの間のネットワーク コストは含まれません。

| キーワード検証の応答 | 説明 |
| ----------------------------- | ----------- |
| 同意 | サービスによって、要求の一部として提供されたオーディオ ストリームにキーワードが存在すると判断されたことを示します。 |
| 拒否 | サービスによって、要求の一部として提供されたオーディオ ストリームにキーワードが存在しないと判断されたことを示します。 |

拒否されたケースでは、サービスによって受け入れられるケースよりも多くのオーディオが処理されるため、待機時間が長くなります。 既定では、キーワード検証で、キーワードを検索するために最大 2 秒のオーディオが処理されます。 2 秒間にキーワードが存在しないと判断された場合、サービスはタイムアウトし、拒否したことを示す応答をクライアントに送ります。

### <a name="using-keyword-verification-with-on-device-models-from-custom-keyword"></a>Custom Keyword からオンデバイス モデルでキーワード検証を使用する

Speech SDK によって、キーワード検証および音声テキスト変換と一緒に Custom Keyword を使用して生成されたオンデバイス モデルをよりシームレスに使用できます。 次の処理が透過的に行われます。
* オンデバイス モデルの結果に基づいたキーワード検証と音声認識へのオーディオ ゲーティング。
* キーワード検証サービスへのキーワードの伝達。
* エンドツーエンドのシナリオの調整を目的とした、追加のメタデータのクラウドへの伝達。 

構成パラメーターを明示的に指定する必要はありません。 必要なすべての情報は、Custom Keyword によって生成されたオンデバイス モデルから自動的に抽出されます。

以下にリンクされているサンプルとチュートリアルでは、Speech SDK の使用方法が示されています。
 * [GitHub 上の音声アシスタントのサンプル](https://github.com/Azure-Samples/Cognitive-Services-Voice-Assistant)
 * [チュートリアル:C# Speech SDK で、Azure Bot Service を使用して構築したアシスタントを音声対応にする](./tutorial-voice-enable-your-bot-speech-sdk.md)
 * [チュートリアル:単純な音声コマンドを使用してカスタム コマンド アプリケーションを作成する](./how-to-develop-custom-commands-application.md)

## <a name="speech-sdk-integration-and-scenarios"></a>Speech SDK の統合とシナリオ

Speech SDK を使用すると、Custom Keyword とキーワード検証サービスで生成された、パーソナライズされたオンデバイス キーワード認識モデルを簡単に利用できます。 製品のニーズを確実に満たすために、この SDK では、次の 2 つのシナリオがサポートされています。

| シナリオ | 説明 | サンプル |
| -------- | ----------- | ------- |
| 音声テキスト変換を使用したエンドツーエンドのキーワード認識 | これは、Custom Keyword でカスタマイズされたオンデバイス キーワード モデルを、Azure Speech のキーワード検証と音声テキスト変換サービスと一緒に使用する場合に最適です。 これは最も一般的なシナリオです。 | <ul><li>[音声アシスタントのサンプル コード。](https://github.com/Azure-Samples/Cognitive-Services-Voice-Assistant)</li><li>[チュートリアル: Azure Bot Service を使用して構築したアシスタントを C# Speech SDK で音声対応にする。](./tutorial-voice-enable-your-bot-speech-sdk.md)</li><li>[チュートリアル: 単純な音声コマンドを使用してカスタム コマンド アプリケーションを作成する。](./how-to-develop-custom-commands-application.md)</li></ul> |
| オフラインのキーワード認識 | これは、Custom Keyword でカスタマイズされたオンデバイス キーワード モデルを使用する、ネットワーク接続がない製品に最適です。 | <ul><li>[Windows UWP での C# サンプル。](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/quickstart/csharp/uwp/keyword-recognizer)</li><li>[Android での Java サンプル](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/quickstart/java/android/keyword-recognizer)</li></ul>

## <a name="next-steps"></a>次の手順

* [Custom Keyword を使用してオンデバイス キーワード認識モデルを生成するには、クイックスタートをお読みください。](custom-keyword-basics.md)
* [音声アシスタントの詳細情報を確認する。](voice-assistants.md)
